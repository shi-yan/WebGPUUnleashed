<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <link rel="shortcut icon" type="image/x-icon" href="/webgpuunleashed/favicon.ico">
    <!-- Primary Meta Tags -->
    <title>WebGPU Unleashed: A Practical Tutorial</title>
    <meta name="title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta name="description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://shi-yan.github.io/webgpuunleashed/Compute/reaction_diffusion.html" />
    <meta property="og:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="og:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="og:image" content="/webgpuunleashed/meta.png" />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="https://shi-yan.github.io/webgpuunleashed/Compute/reaction_diffusion.html" />
    <meta property="twitter:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="twitter:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="twitter:image" content="/webgpuunleashed/meta.png" />

    <link rel="stylesheet" href="/webgpuunleashed/style.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script
        src="https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>


    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/base16/default-dark.min.css"
        integrity="sha512-EF2rc4QyBiRAGUMVm+EjFPBbdVGaN/pwZhtuKyrC/dM+hcwTxI5BsEDUkrMRI77z4VlDAt/qVopePXB5+ZZ8Gw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script src="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js
        "></script>
    <link href="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css
        " rel="stylesheet" />
</head>

<body>
    <div id="menuToggle">
        <input id="menuButton" type="checkbox" />
        <span></span>
        <span></span>
        <span></span>
        <div id="menu-container">
            <ul id="menu">
                <!--<li><a href="#">Home</a></li>
                <li><a href="#">About</a></li>
                <li><a id="test" href="#" onclick="fold(event)">Info</a>
                    <ul class="sub-menu">
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                    </ul>
                </li>
                <li><a href="#">Contact</a></li>
                <li><a href="https://erikterwan.com/" target="_blank">Show me more</a></li>-->
                <li><a href="https://shi-yan.github.io/webgpuunleashed">Home</a></li>
                <li><a href="#" onclick="fold(event)">Intro</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Introduction/the_gpu_driver.html">The GPU Driver</a></li>
                        <li><a href="/webgpuunleashed/Introduction/the_gpu_pipeline.html">The GPU Pipeline</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Basics</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Basics/creating_an_empty_canvas.html">Creating an Empty Canvas</a></li>
                        <li><a href="/webgpuunleashed/Basics/drawing_a_triangle.html">Drawing a Triangle</a></li>
                        <li><a href="/webgpuunleashed/Basics/drawing_a_triangle_with_defined_vertices.html">Drawing a Triangle with Defined Vertices</a></li>
                        <li><a href="/webgpuunleashed/Basics/applying_hardcoded_vertex_colors.html">Applying Hardcoded Vertex Colors</a></li>
                        <li><a href="/webgpuunleashed/Basics/using_different_vertex_colors.html">Using Different Vertex Colors</a></li>
                        <li><a href="/webgpuunleashed/Basics/drawing_a_colored_triangle_with_a_single_buffer.html">Drawing a Colored Triangle with a Single Buffer</a></li>
                        <li><a href="/webgpuunleashed/Basics/understanding_uniforms.html">Understanding Uniforms</a></li>
                        <li><a href="/webgpuunleashed/Basics/working_with_textures.html">Working with Textures</a></li>
                        <li><a href="/webgpuunleashed/Basics/utilizing_transformation_matrices.html">Utilizing Transformation Matrices</a></li>
                        <li><a href="/webgpuunleashed/Basics/implementing_cameras.html">Implementing Cameras</a></li>
                        <li><a href="/webgpuunleashed/Basics/triangle_strips.html">Triangle Strips</a></li>
                        <li><a href="/webgpuunleashed/Basics/front_and_back_face_culling.html">Front and Back Face Culling</a></li>
                        <li><a href="/webgpuunleashed/Basics/depth_testing.html">Depth Testing</a></li>
                        <li><a href="/webgpuunleashed/Basics/index_buffers.html">Index Buffers</a></li>
                        <li><a href="/webgpuunleashed/Basics/loading_3d_models.html">Loading 3D Models</a></li>
                        <li><a href="/webgpuunleashed/Basics/understanding_normals.html">Understanding Normals</a></li>
                        <li><a href="/webgpuunleashed/Basics/lighting.html">Lighting</a></li>
                        <li><a href="/webgpuunleashed/Basics/multi_sample_anti_aliasing.html">Multi-Sample Anti-Aliasing</a></li>
                        <li><a href="/webgpuunleashed/Basics/mipmapping_and_anisotropic_filtering.html">Mipmapping and Anisotropic Filtering</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">2D Techniques</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/2D_Techniques/rendering_to_textures.html">Rendering to Textures</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/orthogonal_cameras.html">Orthogonal Cameras</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/implementing_gaussian_blur.html">Implementing Gaussian Blur</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/video_rendering.html">Video Rendering</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/text_rendering.html">Text Rendering</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/billboarding.html">Billboarding</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/implementing_fake_3d.html">Implementing Fake 3D</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Control</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Control/canvas_resizing.html">Canvas Resizing</a></li>
                        <li><a href="/webgpuunleashed/Control/arcball_camera_control.html">Arcball Camera Control</a></li>
                        <li><a href="/webgpuunleashed/Control/object_picking.html">Object Picking</a></li>
                        <li><a href="/webgpuunleashed/Control/saving_images_and_videos.html">Saving Images and Videos</a></li>
                        <li><a href="/webgpuunleashed/Control/using_web_workers.html">Using Web Workers</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Compute</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Compute/prefix_sum.html">Prefix Sum</a></li>
                        <li><a href="/webgpuunleashed/Compute/radix_sort.html">Radix Sort</a></li>
                        <li><a href="/webgpuunleashed/Compute/reaction_diffusion.html">Reaction Diffusion</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Advanced</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Advanced/stencil_buffer.html">Stencil Buffer</a></li>
                        <li><a href="/webgpuunleashed/Advanced/shadow_mapping.html">Shadow Mapping</a></li>
                        <li><a href="/webgpuunleashed/Advanced/toon_shading.html">Toon Shading</a></li>
                        <li><a href="/webgpuunleashed/Advanced/equirectangular_rendering.html">Equirectangular Rendering</a></li>
                        <li><a href="/webgpuunleashed/Advanced/mega_texture.html">Mega Texture</a></li>
                        <li><a href="/webgpuunleashed/Advanced/transparency_with_depth_peeling.html">Transparency with Depth Peeling</a></li>
                        <li><a href="/webgpuunleashed/Advanced/skeleton_animation.html">Skeleton Animation</a></li>
                        <li><a href="/webgpuunleashed/Advanced/gaussian_splatting.html">Gaussian Splatting</a></li>
                    </ul>
                </li>
                <li><a href="https://shi-yan.github.io/webgpuunleashed/code/code.html" target="_blank">Playground</a></li>
                <li><a href="https://github.com/shi-yan/webgpuunleashed" target="_blank">GitHub Repo</a></li>
            </ul>
        </div>
    </div>

    <div id="article-container">
        <article>
            <h2 >4.2 Reaction Diffusion</h2><p>As a third example, let's explore a scenario where a compute shader collaborates with a rendering shader. The compute shader engages in a straightforward simulation known as reaction-diffusion, while the rendering shader is responsible for visualizing the outcomes of this simulated process.</p><p>In his groundbreaking 1952 paper, "The Chemical Basis of Morphogenesis", Alan Turing proposed a mathematical model to elucidate the emergence of complex patterns and structures within biological systems, particularly in the realm of embryonic development.</p><p>Turing's model explores the interaction of two chemicals undergoing reaction and diffusion processes. This concept, commonly termed the Turing pattern, has become associated with reaction-diffusion systems. Reaction-diffusion equations delineate how concentrations of substances evolve over space and time, influenced by both chemical reactions and substance diffusion. In the realm of pattern formation, Turing's concepts laid the groundwork for comprehending how elementary local interactions could give rise to the development of intricate patterns within biological systems. Despite the seeming simplicity of the reaction-diffusion system, Turing theorized that it underlies the intricate patterns observed in animals, such as zebras and leopards.</p><p>In our simulation, we simulate the behavior of two chemicals, A and B. Specifically, two molecules of B catalyze the conversion of one molecule of A into B. Chemical A is introduced into the system at a specified rate, while chemical B exits the system at a distinct rate. This dynamic interplay between the addition of chemical A and the removal of chemical B contributes to the evolving state of the simulation, reflecting the intricate balance and interactions within the simulated reaction-diffusion system.</p><p>However, we don't want to model individual molecules. Instead, we divide the entire space into small units, with each unit representing a pixel. For each time step interval, we update the amount of A and B in each pixel, and their concentrations will be visualized using color. The whole process can be described by the following equations:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
A^\prime &= A + (D_A \nabla^2 A - A B^2 + f(1-A)	)\Delta	t \\
B^\prime &= B + (D_B \nabla^2 B + A B^2 - (K+f)B)\Delta	t
\end{aligned}</code></p><p>This first equation models the behavior of chemical A. For each unit time <code class="language-math math-inline">\Delta t</code>, the diffused amount is defined by <code class="language-math math-inline">D_A \nabla^2 A</code>, where <code class="language-math math-inline">D_A \nabla^2</code> is called the Laplacian. The Laplacian is essentially a 3x3 matrix used to calculate a weighted sum of each 3x3 neighborhood. If the center pixel has a higher concentration than its neighbors, we allow more chemical to flow into the neighboring pixels. Conversely, if the neighbors have a higher concentration, the chemical flows from the neighbors into the central pixel.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_laplacian.png" original_src="laplacian.png" alt="The Laplacian" sources='[]' /><div class="img-title">The Laplacian</div></div></p><p>The second part of the equation models the chemical reaction. For the reaction to occur, two molecules of B and one molecule of A are required. Since we are modeling the chemicals by their concentration, we can interpret this as the probability of encountering a molecule. This makes sense because the higher the concentration of a chemical, the greater the likelihood of a molecule encounter. Therefore, <code class="language-math math-inline">A B^2</code> represents the probability of one A molecule encountering two B molecules.</p><p>Finally, we add new molecules of A into the system at a rate of <code class="language-math math-inline">f(1-A)</code>. This ensures that the concentration of A will not exceed 1.0 because if it does, the rate will become negative to counteract the effect.</p><p>Similarly, we remove B molecules at a rate of <code class="language-math math-inline">(K+f)B</code>. Since <code class="language-math math-inline">K + f > f</code>, this ensures that B is removed faster than A is added.</p><p><code class="language-math math-inline">\Delta t</code> is the time interval.</p><p>Now let's look at the code. The purpose of this exercise is to demonstrate how a compute shader can work in conjunction with a rendering shader. Two storage textures are involved in the program. Unlike a normal texture, a storage texture can be written to. We use two textures; for each shader invocation, one texture serves as the input, containing the current chemical concentrations. We update the concentrations based on the equations and write the results into the other storage texture. Then we trigger the rendering program for visualization. In consecutive runs, we switch the roles of the two textures. The previous input texture becomes the output and vice versa.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=11>enable chromium_experimental_read_write_storage_texture;

@binding(0) @group(0) var texSrc : texture_storage_2d&lt;rg32float, read&gt;;
@binding(1) @group(0) var texDst : texture_storage_2d&lt;rg32float, write&gt;;
@binding(2) @group(0) var&lt;uniform&gt; drawPos : vec3&lt;f32&gt;;

const imageSize:i32 = 1024;
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=10:16#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:11-17 Writable Storage Texture for Results</a></div></div><p>First, let's define the inputs of the compute shader. In the initial line, we need to explicitly enable the writable storage texture feature, as this feature is still experimental. This is not the only step required to enable this feature; we will also need to request it when we initialize the device, which we will see later.</p><p>As previously mentioned, there are two texture maps: one for inputs and one for outputs. Note that the format of the two texture maps is rg32f. Since we have two types of chemicals, we use two channels to represent them. We choose 32f for numerical accuracy.</p><p>We also have a drawPos, which defines a position. This position represents the current brush location. Because we want our demo to be interactive, we allow users to draw on the canvas by adding chemical A at the brush's position.</p><p>For the image size, we hardcode it to 1024.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=18>@compute @workgroup_size(16, 16)
fn main(@builtin(global_invocation_id) GlobalInvocationID : vec3&lt;u32&gt;) {

      var centerY:i32 = i32(GlobalInvocationID.y);
      var centerX:i32 = i32(GlobalInvocationID.x);

      if (drawPos.z &gt; 0.5) {
          var radius:f32 = sqrt((f32(centerX) - drawPos.x)*(f32(centerX) - drawPos.x) +
          (f32(centerY) - drawPos.y)*(f32(centerY) - drawPos.y));

          if (radius &lt; 5.0) {
              textureStore(texDst, vec2i(GlobalInvocationID.xy), vec4&lt;f32&gt;(0.0,1.0,0.0,0.0));
              return;
          }
      }
</pre></code><div class="code-fragments-separator">• • •</div><pre><code class="language-javascript code-block" startNumber=68>}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=17:31,67:67#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:18-68 2D Compute Kernel</a></div></div><p>Next, we create a compute kernel function. Notice that we are using a 2D workgroup of size 16x16. The 2D workgroup is suitable because our problem involves calculating pixel values for a 2D texture map. Although 16x16 may seem small compared to the texture map size of 1024, this size is the maximum workgroup size we can request. This is due to the maxComputeInvocationsPerWorkgroup limitation, which is 256 (the maximum value of the product of the workgroup dimensions for a compute stage).</p><p>Next, we handle the brush input. If the user is actively drawing (determined by drawPos.z > 0.5), we compute the distance between the current pixel (centerX, centerY) and drawPos.xy. If this distance is less than 5.0, we set the texture color to (0.0, 1.0), indicating that the pixel is fully concentrated with molecule B.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=35>for(var y = -1; y&lt;= 1;y++) {
    var accessY:i32 = centerY + y;
    if (accessY &lt; 0) {
        accessY = imageSize-1;
    } else if (accessY &gt;= imageSize) {
        accessY = 0;
    }

    for(var x = -1; x&lt;=1;x++) {
        var accessX:i32 =centerX+ x;

        if (accessX &lt; 0) {
            accessX = imageSize-1;
        } else if (accessX &gt;= imageSize) {
            accessX = 0;
        }
        var rate = -1.0;
        if (x==0 &amp;&amp; y == 0) {
            rate = -1.0;
        } else if (x ==0 || y==0) {
            rate = 0.2;
        } else {
            rate = 0.05;
        }
        data += textureLoad(texSrc, vec2i(accessX, accessY)).rg * rate;
    }
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=34:60#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:35-61 Loop Through the 3x3 Neighborhood</a></div></div><p>Here, we loop through the 3x3 neighborhood surrounding the current pixel. We ensure that if the indices fall outside the image boundaries, they wrap around to the opposite edge of the image.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=51>var rate = -1.0;
if (x==0 &amp;&amp; y == 0) {
    rate = -1.0;
} else if (x ==0 || y==0) {
    rate = 0.2;
} else {
    rate = 0.05;
}
data += textureLoad(texSrc, vec2i(accessX, accessY)).rg * rate;
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=50:58#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:51-59 Concentration Due to Diffusion</a></div></div><p>We then calculate the change in concentration due to diffusion. The rate variable determines how much influence each neighboring pixel has based on its distance from the center pixel.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=62>const f:f32 = 0.055;
const k:f32 = 0.062;
data = vec2&lt;f32&gt;(data.x- original.x*original.y*original.y
    + f * (1.0 - original.x),
     data.y*0.5 + original.x*original.y*original.y - (k+f) * original.y) + original;
textureStore(texDst, vec2i(GlobalInvocationID.xy), vec4&lt;f32&gt;(data,0.0,0.0));
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=61:66#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:62-67 Concentration Due to Reaction</a></div></div><p>Finally, we compute the concentration changes due to the reaction and update the system accordingly. The result is then written to the output texture map.</p><p>For visualization, the rendering shader functions similarly to a basic texture mapping shader. It displays the results from the compute shader by mapping them onto a quad. Note that for the rendering shader, the texture used does not need to be a storage texture; a standard texture map type suffices.</p><p>Now let's look at pipeline configuration.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=107>const feature = "chromium-experimental-read-write-storage-texture";
const adapter = await navigator.gpu.requestAdapter();
console.log(adapter);
if (!adapter.features.has(feature)) {
    showWarning("This sample requires a chrome experimental feature. Please restart chrome with the --enable-dawn-features=allow_unsafe_apis flag.");
    throw new Error("Read-write storage texture support is not available");
}
const device = await adapter.requestDevice({
    requiredFeatures: [feature],
});
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=106:115#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:107-116 Request Storage Texture</a></div></div><p>First, as previously mentioned, it's essential to request support for the storage texture feature when creating the GPU device.</p><p>Next, configure the uniforms for the compute stage as follows:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=118>const context = configContext(device, canvas)

// create shaders
let shaderModule = shaderModuleFromCode(device, 'shader');

let uniformBindGroupLayoutCompute = device.createBindGroupLayout({
    entries: [
        {
            binding: 0,
            visibility: GPUShaderStage.COMPUTE,
            storageTexture: {
                access: "read-only",
                format: "rg32float",
            }
        },
        {
            binding: 1,
            visibility: GPUShaderStage.COMPUTE,
            storageTexture: {
                access: "write-only",
                format: "rg32float",
            }
        },
        {
            binding: 2,
            visibility: GPUShaderStage.COMPUTE,
            buffer: {}
        }
    ]
});
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=117:146#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:118-147 Configuring Uniform Bind Group Layout</a></div></div><p>This configuration is akin to previous setups, with particular attention paid to the storage texture’s specification. The input texture is designated as read-only, while the output texture is set to write-only. The format used is rg32float, ensuring sufficient precision for the chemical concentrations.</p><p>Next, we proceed to initialize the input texture. This step is crucial as it assigns initial chemical concentrations to the texture. By doing this, the simulation can generate patterns autonomously, even in the absence of user interaction. This setup allows the system to develop and evolve patterns based on predefined initial conditions, facilitating a meaningful demonstration of the reaction-diffusion process.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=148>const srcTextureDesc = {
    size: [1024, 1024, 1],
    dimension: '2d',
    format: "rg32float",
    usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.TEXTURE_BINDING
};

let textureValues = [];

for (let y = 0; y &lt; 1024; ++y) {
    for (let x = 0; x &lt; 1024; ++x) {
        if (x &gt; 302 &amp;&amp; x &lt; 532 &amp;&amp; y &gt;= 302 &amp;&amp; y &lt; 532) {
            textureValues.push(0.0);
            textureValues.push(1.0);
        }
        else {
            textureValues.push(1.0);
            textureValues.push(0.0);
        }
    }
}

let srcTexture = device.createTexture(srcTextureDesc);

device.queue.writeTexture({ texture: srcTexture }, new Float32Array(textureValues), {
    offset: 0,
    bytesPerRow: 1024 * 8,
    rowsPerImage: 1024
}, { width: 1024, height: 1024 });
await device.queue.onSubmittedWorkDone();
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=147:176#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:148-177 Seed the Initial Chemical Concentration</a></div></div><p>To initialize the texture map, we define a rectangular area [302, 532, 302, 532] within which chemical B is assigned, and outside this rectangle, chemical A is used. This setup is straightforward and ensures that the initial conditions for the simulation are well-defined. The resulting data is then loaded into the input texture.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=178>const dstTextureDesc = {
    size: [1024, 1024, 1],
    dimension: '2d',
    format: "rg32float",
    usage: GPUTextureUsage.COPY_SRC | GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.TEXTURE_BINDING
};

let dstTexture = device.createTexture(dstTextureDesc);

let drawPosUniformBuffer = createGPUBuffer(device, drawPos, GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST);
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=177:186#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:178-187 Create a Output Texture</a></div></div><p>Next, we create the output texture, which doesn’t require any initialization. To manage the alternating roles of the input and output textures between consecutive invocations, we set up two uniform bind groups:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=188>let uniformBindGroupCompute0 = device.createBindGroup({
    layout: uniformBindGroupLayoutCompute,
    entries: [
        {
            binding: 0,
            resource: srcTexture.createView()
        },
        {
            binding: 1,
            resource: dstTexture.createView()
        },
        {
            binding: 2,
            resource: {
                buffer: drawPosUniformBuffer
            }
        }
    ]
});

let uniformBindGroupCompute1 = device.createBindGroup({
    layout: uniformBindGroupLayoutCompute,
    entries: [
        {
            binding: 0,
            resource: dstTexture.createView()
        },
        {
            binding: 1,
            resource: srcTexture.createView()
        },
        {
            binding: 2,
            resource: {
                buffer: drawPosUniformBuffer
            }
        }
    ]
});
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=187:225#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:188-226 Create Two Uniform Bind Group for Alternating Usage</a></div></div><p>Following this, we need to set up the compute shader pipeline. As this process mirrors previous examples, the code is omitted here. Once the compute shader is configured, we proceed to configure the bind group layout for the rendering shader:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=236>const sampler = device.createSampler({
    addressModeU: "clamp-to-edge",
    addressModeV: "clamp-to-edge",
    addressModeW: "clamp-to-edge",
    magFilter: "nearest",
    minFilter: "nearest",
    mipmapFilter: "nearest"
});

let uniformBindGroupLayoutRender = device.createBindGroupLayout({
    entries: [
        {
            binding: 0,
            visibility: GPUShaderStage.FRAGMENT,
            texture: {
                sampleType: "unfilterable-float",
            }
        },
        {
            binding: 1,
            visibility: GPUShaderStage.FRAGMENT,
            sampler: {
                type: "non-filtering",
            }
        }
    ]
});
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=235:261#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:236-262 Sampler and Bind Group</a></div></div><p>Unless the feature "float32-filterable" is enabled, the texture format rg32float can only use unfilterable-float for its sampleType. Consequently, the sampler must employ "nearest" for filtering and be of type "non-filtering." Filtering in computer graphics involves interpolating the values defined on the texture map to determine what is read in a shader program. During texture mapping, a texture lookup determines where each pixel center falls on the texture. On texture-mapped polygonal surfaces, typical in 3D games and movies, each pixel (or subordinate pixel sample) corresponds to some triangles and a set of barycentric coordinates, which define its position within the texture. Since the textured surface may be at an arbitrary distance and orientation relative to the viewer, one pixel does not usually align directly with one texel. Filtering is necessary to determine the best color for the pixel and to avoid artifacts such as blockiness, jaggies, or shimmering.</p><p>The relationship between a pixel and the texel(s) it represents on the screen varies based on the textured surface's position relative to the viewer. For example, when a square texture is mapped onto a square surface, and the viewing distance makes one screen pixel exactly the same size as one texel, no filtering is required. However, if the texels are larger than the screen pixels (texture magnification), or if each texel is smaller than a pixel (texture minification), appropriate filtering is needed. Graphics APIs like OpenGL allow programmers to set different filters for magnification and minification.</p><p>Even when pixels and texels are the same size, a pixel may not align perfectly with a texel and may cover parts of up to four neighboring texels. Therefore, filtering is still necessary.</p><p>In our demo, we will bypass the extra requirement of enabling "float32-filterable" by reading values directly from the texture map without interpolation.</p><p>For bind groups, we need to create two separate groups to alternate between the two texture maps:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=263>let uniformBindGroupRender0 = device.createBindGroup({
    layout: uniformBindGroupLayoutRender,
    entries: [
        {
            binding: 0,
            resource: dstTexture.createView()
        },
        {
            binding: 1,
            resource: sampler
        }
    ]
});

let uniformBindGroupRender1 = device.createBindGroup({
    layout: uniformBindGroupLayoutRender,
    entries: [
        {
            binding: 0,
            resource: srcTexture.createView()
        },
        {
            binding: 1,
            resource: sampler
        }
    ]
});
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=262:288#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:263-289 Bind Group Creation</a></div></div><p>The remaining code for setting up the rendering pipeline is similar to previous examples, so I'll omit the details. Now, let's address implementing brush drawing. The pattern produced by the reaction-diffusion process is sensitive to the initial chemical concentration, so we need to allow users to alter this concentration to modify the pattern. To achieve this, we add brush drawing capabilities.</p><p>Here’s how we handle mouse input for brush drawing:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=405>let prevX = 0.0;
let prevY = 0.0;
let isDragging = false;

canvas.onmousedown = (event) =&gt; {
    var rect = canvas.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const y = event.clientY - rect.top;


    isDragging = true;

}

canvas.onmousemove = (event) =&gt; {
    if (isDragging != 0) {
        var rect = canvas.getBoundingClientRect();
        const x = event.clientX - rect.left;
        const y = event.clientY - rect.top;
        drawPos.set([x, y, 1.0], 0);
    }
}

canvas.onmouseup = (event) =&gt; {
    isDragging = 0;
    drawPos.set([0.0, 0.0, 0.0], 0);
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=404:430#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:405-431 Mouse Event Handling</a></div></div><p>The implementation is straightforward: we update the uniform drawPos to (x, y, 1.0) when the user is drawing, and set it to (0.0, 0.0, 0.0) when not. In the shader code, the third component of this vector (drawPos.z > 0.5) is used to check if the brush is actively touching the canvas.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=367>const passEncoder = commandEncoder.beginComputePass(
    {}
);
passEncoder.setPipeline(computePipeline);
if (frame % 2 == 0) {
    passEncoder.setBindGroup(0, uniformBindGroupCompute0);
}
else {
    passEncoder.setBindGroup(0, uniformBindGroupCompute1);
}
passEncoder.dispatchWorkgroups(64, 64);
passEncoder.end();

device.queue.submit([commandEncoder.finish()]);

const commandEncoder2 = device.createCommandEncoder();

const passEncoder2 = commandEncoder2.beginRenderPass(renderPassDesc);
passEncoder2.setViewport(0, 0, canvas.width, canvas.height, 0, 1);
passEncoder2.setPipeline(renderPipeline);
if (frame % 2 == 0) {
    passEncoder2.setBindGroup(0, uniformBindGroupRender0);
}
else {
    passEncoder2.setBindGroup(0, uniformBindGroupRender1);
}
passEncoder2.setVertexBuffer(0, positionBuffer);
passEncoder2.draw(4, 1);
passEncoder2.end();
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/webgpuunleashed/code/code.html?highlight=366:394#4_02_reaction_diffusion">4_02_reaction_diffusion/index.html:367-395 Command Submission</a></div></div><p>The rendering process consists of two distinct passes. The first pass performs the compute operations and updates the output texture map, while the second pass renders the updated texture map onto the screen. Note that the compute shader uses a workgroup size of 16x16, and we dispatch the workgroups in a 2D formation of 64x64. This is because 64x16 equals 1024, which matches the size of our textures.</p><p>This completes one frame of rendering. For the next frame, we will switch the roles of the input and output textures: the output texture will become the input, and the input texture will become the output.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="placeholder.jpg" alt="Show 3 Steps of Diffusion" sources='[]' /><div class="img-title">Show 3 Steps of Diffusion</div></div></p>
        </article>

        <div class="older_newer_link_section">
            <div class="older_newer_link_left">
                <p>
                    <svg xmlns="http://www.w3.org/2000/svg" height="12" width="11" fill="#dadadb"
                        viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
                        <path
                            d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" />
                    </svg>
                    PREV POST
                </p>
                <p>
                    <a class="older_newer_link" href="/webgpuunleashed/Compute/radix_sort.html">Radix Sort</a>
                </p>
            </div>

            <div class="older_newer_link_right">
                <p>
                    NEXT POST
                    <svg xmlns="http://www.w3.org/2000/svg" height="12" width="11" fill="#dadadb"
                        viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
                        <path
                            d="M438.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-160-160c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L338.8 224 32 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l306.7 0L233.4 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l160-160z" />
                    </svg>
                </p>
                <p>
                    <a class="older_newer_link" href="/webgpuunleashed/Advanced/stencil_buffer.html">Stencil Buffer</a>
                </p>
            </div>
        </div>

        <a href="https://github.com/shi-yan/webgpuunleashed/discussions" target="_blank" class="comment"><svg
            style="margin-right:10px;vertical-align: middle;" xmlns="http://www.w3.org/2000/svg" height="32"
            width="32" fill="#dadadb"
            viewBox="0 0 480 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
            <path
                d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z" />
        </svg> Leave a Comment on Github</a>
    </div>
    <!-- The Modal -->
    <div id="img-modal" class="modal">
        <!-- The Close Button -->
        <span class="close" id="img-close">&times;</span>
        <!-- Modal Content (The Image) -->
        <img class="modal-content" id="img01">

        <!-- Modal Caption (Image Text) -->
        <div id="caption"></div>
    </div>
    <script>
        function fold(e) {
            const sub = e.currentTarget.parentElement.getElementsByTagName("ul")[0];
            console.log("sub", e.currentTarget, sub);
            if (sub.style.display === "block") {
                sub.style.display = "none";
            } else {
                sub.style.display = "block";
            }
        }
    
        window.addEventListener('click', (e) => {
           // const sub = e.currentTarget.parentElement.getElementsByTagName("ul")[0];
            document.getElementById("menuButton").checked = false;
        });
    
        document.getElementById("menu-container").addEventListener('click',(event) => {
            event.stopPropagation();
        });

        document.getElementById("menuButton").addEventListener('click', (event) => {
            event.stopPropagation();
        });
       
        function openImage(img) {
            let modal = document.getElementById("img-modal");
            let modalImg = document.getElementById("img01");
            modal.style.display = "block";
            if (img.getAttribute("original_src")) {
                modalImg.src = img.getAttribute("original_src");
            } else {
                modalImg.src = img.src;
            }
            let captionText = document.getElementById("caption");

            captionText.innerText = img.alt;

            let sources = JSON.parse(img.getAttribute("sources"));

            for (let i = 0; i < sources.length; ++i) {
                if (sources.length == 1) {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE</a>";
                } else {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE " + (i + 1) + "</a>";
                }
            }
        }
        // Get the <span> element that closes the modal
        var closeButton = document.getElementById("img-close");

        // When the user clicks on <span> (x), close the modal
        closeButton.onclick = function () {
            var modal = document.getElementById("img-modal");
            modal.style.display = "none";
        }
    </script>

    <script type="module">
        const macros = {};
        const mathElementsBlock = document.getElementsByClassName("math-block");
        for (let element of mathElementsBlock) {
            katex.render(element.textContent, element, {
                throwOnError: false,
                displayMode: true,
                macros
            });
        }

        const mathElementsInline = document.getElementsByClassName("math-inline");
        for (let element of mathElementsInline) {
            katex.render(element.textContent, element, {
                throwOnError: false,
                macros
            });
        }

        hljs.highlightAll();
        // hljs.initLineNumbersOnLoad();
        const codeBlocks = document.getElementsByClassName("code-block");
        for (let i = 0; i < codeBlocks.length; ++i) {
            if (codeBlocks[i].hasAttribute("startnumber")) {
                const startFrom = codeBlocks[i].getAttribute("startnumber");
                hljs.lineNumbersBlock(codeBlocks[i], { startFrom: parseInt(startFrom, 10) });
            } else {
                hljs.lineNumbersBlock(codeBlocks[i]);
            }
        }

    </script>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-G278P1YSJ6"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag() { dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'G-G278P1YSJ6');
</script>
</body>

</html>