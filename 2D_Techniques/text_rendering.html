<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <!-- Primary Meta Tags -->
    <title>WebGPU Unleashed: A Practical Tutorial</title>
    <meta name="title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta name="description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://shi-yan.github.io/WebGPUUnleashed/2D_Techniques/text_rendering.html" />
    <meta property="og:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="og:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="og:image" content="/WebGPUUnleashed/meta.png" />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="https://shi-yan.github.io/WebGPUUnleashed/2D_Techniques/text_rendering.html" />
    <meta property="twitter:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="twitter:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="twitter:image" content="/WebGPUUnleashed/meta.png" />

    <link rel="stylesheet" href="/WebGPUUnleashed/style.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>


    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/base16/default-dark.min.css"
        integrity="sha512-EF2rc4QyBiRAGUMVm+EjFPBbdVGaN/pwZhtuKyrC/dM+hcwTxI5BsEDUkrMRI77z4VlDAt/qVopePXB5+ZZ8Gw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script src="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js
        "></script>
    <link href="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css
        " rel="stylesheet" />

    <script>
        function fold(e) {
            const sub = e.currentTarget.parentElement.getElementsByTagName("ul")[0];
            console.log("sub", e.currentTarget, sub);
            if (sub.style.display === "block") {
                sub.style.display = "none";
            } else {
                sub.style.display = "block";
            }
        }
    </script>
</head>

<body>
    <nav role="navigation">
        <div id="menuToggle">
            <input type="checkbox" />
            <span></span>
            <span></span>
            <span></span>
            <ul id="menu">
                <!--<li><a href="#">Home</a></li>
                <li><a href="#">About</a></li>
                <li><a id="test" href="#" onclick="fold(event)">Info</a>
                    <ul class="sub-menu">
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                    </ul>
                </li>
                <li><a href="#">Contact</a></li>
                <li><a href="https://erikterwan.com/" target="_blank">Show me more</a></li>-->
                <li><a href="#" onclick="fold(event)">Intro</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Introduction/the_gpu_driver.html">The GPU Driver</a></li>
                        <li><a href="/WebGPUUnleashed/Introduction/the_gpu_pipeline.html">The GPU Pipeline</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Basics</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Basics/creating_an_empty_canvas.html">Creating an Empty Canvas</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/drawing_a_triangle.html">Drawing a Triangle</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/drawing_a_triangle_with_defined_vertices.html">Drawing a Triangle with Defined Vertices</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/applying_hardcoded_vertex_colors.html">Applying Hardcoded Vertex Colors</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/using_different_vertex_colors.html">Using Different Vertex Colors</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/drawing_a_colored_triangle_with_a_single_buffer.html">Drawing a Colored Triangle with a Single Buffer</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/understanding_uniforms.html">Understanding Uniforms</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/working_with_textures.html">Working with Textures</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/utilizing_transformation_matrices.html">Utilizing Transformation Matrices</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/implementing_cameras.html">Implementing Cameras</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/triangle_strips.html">Triangle Strips</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/front_and_back_face_culling.html">Front and Back Face Culling</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/depth_testing.html">Depth Testing</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/index_buffers.html">Index Buffers</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/loading_3d_models.html">Loading 3D Models</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/understanding_normals.html">Understanding Normals</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/lighting.html">Lighting</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/multi_sample_anti_aliasing.html">Multi-Sample Anti-Aliasing</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/mipmapping_and_anisotropic_filtering.html">Mipmapping and Anisotropic Filtering</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">2D Techniques</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/2D_Techniques/rendering_to_textures.html">Rendering to Textures</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/orthogonal_cameras.html">Orthogonal Cameras</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/implementing_gaussian_blur.html">Implementing Gaussian Blur</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/video_rendering.html">Video Rendering</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/text_rendering.html">Text Rendering</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/billboarding.html">Billboarding</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/implementing_fake_3d.html">Implementing Fake 3D</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Control</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Control/canvas_resizing.html">Canvas Resizing</a></li>
                        <li><a href="/WebGPUUnleashed/Control/arcball_camera_control.html">Arcball Camera Control</a></li>
                        <li><a href="/WebGPUUnleashed/Control/object_picking.html">Object Picking</a></li>
                        <li><a href="/WebGPUUnleashed/Control/saving_images_and_videos.html">Saving Images and Videos</a></li>
                        <li><a href="/WebGPUUnleashed/Control/using_web_workers.html">Using Web Workers</a></li>
                        <li><a href="/WebGPUUnleashed/Control/error_handling_and_limits.html">Error Handling and Limits</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Compute</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Compute/prefix_sum.html">Prefix Sum</a></li>
                        <li><a href="/WebGPUUnleashed/Compute/radix_sort.html">Radix Sort</a></li>
                        <li><a href="/WebGPUUnleashed/Compute/reaction_diffusion.html">Reaction Diffusion</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Advanced</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Advanced/stencil_buffer.html">Stencil Buffer</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/shadow_mapping.html">Shadow Mapping</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/toon_shading.html">Toon Shading</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/equirectangular_rendering.html">Equirectangular Rendering</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/mega_texture.html">Mega Texture</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/transparency_with_depth_peeling.html">Transparency with Depth Peeling</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/skeleton_animation.html">Skeleton Animation</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/normal_mapping_and_bump_mapping.html">Normal Mapping and Bump Mapping</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/gaussian_splatting.html">Gaussian Splatting</a></li>
                    </ul>
                </li>
            </ul>
        </div>
    </nav>
    <div id="article-container">
        <article>
            <h2 >2.4 Text Rendering</h2><p>You might be surprised to discover that text rendering using graphics API like WebGPU or similar is not that easy. And yet, displaying text seems to be a very fundamental need even for 3D use cases. we need it on ui, and for labels in visualization and for 2D content in games, etc. as language is the most provassive content that has the lowest bar to create, rendering text is unavoidable.</p><p>But text rendering is not a ready function provided by these graphics API. in fact, you have to do a lot of work to do it perfectly.</p><p>in this chapter, we will look at the most preliminary way of supporting text and I also hope to cover some background on what's needed to implement a full featured text rendering system and what are the trade offs between different approaches.</p><p>let's first talk about a full text rendering process. on our system, we have a lot of font files. usually, each font file covers only a portion of all possible characters in one or a few languages, but not all of them. when we type a text, the first step is determine which font files to load the characters from. we need to check if the character we want presents in the top priority font file. if we don't find the characters defined in the font file, for example, we type a mix of English and Chinese characters, likely the top priority english font won't have the chinese characters, we will have to search for other alternatives. This step is called font fall back. we will end up have a set of candidate font files for rendering something as simple as a sentence.</p><p>what's saved in a font file? it is usually a database of glyphs and their measurements. notice that a glyph is not necessarily the same as a character. it is a partial character that we can use to assemble a character. For example, in an emoji font file, a smelling face waring sunglasses could be represented by a face and sunglasses glyphs. this hugely increased the complexity of font rendering. next, we will have to go through a process called text shaping, which refers to the process of transforming text characters from their basic form (glyphs) into their appropriate contextual forms, taking into account factors such as font styles, ligatures, character positioning, and language-specific rules. this is especially difficult to do right, when there are multiple fonts and languages involved. And next is font rasterization. most of the glyphs are kept as geometry data, such as line segments and curves. the benefit of using geometry is that it is immune to resizing. But others might be in a bitmap format, common seen on emojis, which are essentially small pictures. implementing a robust rendering function has to be able to mix different formats nicely.</p><p>Text rendering system usually incorporate a character caches system. for all characters that have been seen already, the cache system establish a lookup table to avoid repeatedly rasterizing them. this is more efficient for small alphabet languages, but difficult for languages like chinese which has a lot of more characters. Also if the system needs to handle font resizing, the cache has to be invalidated to rerender characters in the correct resolution.</p><p>And finally, we need to consider how to format long text, or text wrapping and reflow, if the text container can change its size.</p><p>because text rendering is so difficult, people seldom do it from scratch. operating system usually provide an implementation, but a good cross-platform choice is scare. there are other libraries that can handle one of the rendering stage, for example text shaping. but most of the tools are developed for the cpp world. we have less choice when it comes to the web.</p><p>in the context of 3D graphics, we usually have to make trade offs. in games, for example, we may only support english to simplify character cache. or we may choose monospaced fonts in a terminal, IDE type of application to simplify text shaping.</p><p>in this tutorial, we only covers the most basic implementation of text rendering. we will rely on a 2D canvas to draw a piece of text and create a texture map based on it. this way, we can leverage the existing text functional provided by the web browser to handle all the aforementioned complexity. The draw back of this approach is that for text dense application, this approach will create a lot of texture maps and excuse gpu memory quickly. and for dynamic text content, repeatedly rasterizing text using a 2d canvas and creating texture maps might be slow. also we are limited to the font styles that are available in a 2D context. the method is more suitable for visualization use cases, to render labels or simple uis.</p><p>now let's look at the code</p><pre><code class="language-javascript code-block">    function printText(device, text) {
        const width = 320;
        const height = 240;
        const canvas = new OffscreenCanvas(width, height);
        const ctx = canvas.getContext("2d");
        ctx.clearRect(0, 0, width, height);
        ctx.globalAlpha = '0.5';
        ctx.font = 'bold 16px Arial';
        ctx.fillStyle = 'white';
        const textMeasure = ctx.measureText(text); // TextM

        console.log("texture measure", textMeasure);
        console.log("width", Math.ceil(textMeasure.width))
        ctx.fillText(text, 0, 16);

        const textureDescriptor = {
            size: { width: nearestPowerOf2(Math.ceil(textMeasure.width)), height: 16 },
            format: 'rgba8unorm',
            usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT
        };

        const texture = device.createTexture(textureDescriptor);
        device.queue.copyExternalImageToTexture({ source: canvas, origin: { x: 0, y: 0 } }, { texture }, textureDescriptor.size);

        return texture;
    }</code></pre><p>first, let's define a function that given a piece of text, it renders the text using an offscreen canvas and a 3d canvas, and then loads the result onto a texture map. we first has to define a size that is large enough to hold the text we want to render. this is a tricky task if the text is dynamicaly created during runtime, i.e. input by user. this is another drawback of this method. but since in this example, we only deal with static text predetermined, we can choose a large enough size based on trial and error approach. then we create an offscreen canvas and a 2d context based on this size. after that we configure the font and fillStyle and measure the text we will be render using the measureText call. this will determines the size required for the texture. notice again that RENDER_ATTACHMENT is required for calling copyExternalImageToTexture. finally we load the canvas to the texture map and return it.</p><pre><code class="language-javascript code-block">        const colorState = {
            format: 'bgra8unorm',
            blend: {
                alpha: {
                    operation: "add",
                    srcFactor: 'one',
                    dstFactor: 'one-minus-src',
                },
                color: {
                    operation: "add",
                    srcFactor: 'one',
                    dstFactor: 'one-minus-src',
                }
            }
        };</code></pre><p>next, let's look at how to define the pipeline. here I omit what we have already learned, and focus on the difference. This time, when defining the colorState for the pipeline, we need to specify alpha blending. we need to talk about alpha blending. the output of the fragment stage is a color with an alpha channel, i.e. it can be transparent. we can configure the pipeline to specify what we want to do to apply this transparent color onto the framebuffer or how to blend it with the existing framebuffer. if we don't enable alpha blending at all, which is the default behavior, everything will be rendered as opaque pixels. but if we want to draw partially transparent texture, or semitransparent objects, we will have to enable alpha blending. this is specifically important for the text rendering case, because only the strokes should be opaque, for other areas, we want to be able to see through the text and see the background.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="placeholder.jpg" alt="Show an Illustration of Src and Dst Blending" sources='[]' /><div class="img-title">Show an Illustration of Src and Dst Blending</div></div></p><p>notice that if what we want is rendering semi transparent objects, such as glass objects, alpha blending alone will not achieve that. we will talk about supporting transparency in the last chapter. to understand alpha blending, we need to understand two concepts that I personally think is very confusing. blend source and blend destination. here blend source means what's outputted by the fragment shader and the blend destination is referring to what's existing on the framebuffer. there could be also a blend constant, which is a constant value specified.</p><p>we can assign different blending behaviors to the alpha channel and the color channel. and for a configuration, we need to specify three things: an operation, a srcFactor and a dstFactor. the final color or alpha can be obtained by</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
f_{sc} * C_s \bigodot f_{dc} * C_d &= C \\
f_{sa} * A_s \bigodot f_{da} * A_d &= A \\
\end{aligned}</code></p><p>where <code class="language-math math-inline">f_{sc}</code> and <code class="language-math math-inline">f_{sa}</code> are srcFactors we defined for color and alpha channels and <code class="language-math math-inline">f_{dc}</code> and <code class="language-math math-inline">f_{da}</code> are the dstFactors, and <code class="language-math math-inline">\bigodot</code> is an operation.</p><p>Let's explore some common alpha blending formulas used in real-time computer graphics.</p><p>Additive blending is similar to how colors combine in light, resulting in a brighter color as the two colors are added together. This process mimics how our monitors create colors by combining red, green, and blue at varying intensities. Additive blending is often used in 3D rendering for effects like light emission in particles or creating a glow effect. It is represented by the equation <code class="language-math math-inline">S + D</code>, where <code class="language-math math-inline">S</code> is the source color and alpha, and <code class="language-math math-inline">D</code> is the destination.</p><p>Multiplicative blending mimics how light interacts with absorbing mediums or filters. This blending operation tends to darken colors and is useful for preserving dark areas like shadows. In the printing industry, colors are added in multiple passes, resulting in darker colors, similar to multiplicative blending. It is represented by the equation <code class="language-math math-inline">S * D</code>.</p><p>Interpolative blending, as the name suggests, blends between two colors based on alpha. It is typically used when placing a semi-transparent foreground over a background or simulating tinted glass. The source alpha controls the visibility of the foreground. Unlike other modes, it depends on the order in which objects are drawn. To achieve accurate results, draw the furthest objects first, followed by closer ones. Interpolative blending is specified by the equation <code class="language-math math-inline">A_s * S + (1 - A_s) * D</code>.</p><p>These are just a few examples of blending effects. To explore more, consider experimenting with Photoshop, where you can apply different blend modes to layers. This can help you visualize how each mode affects the overall appearance of your graphics.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="placeholder.jpg" alt="Show an Image of Photoshop Layers" sources='[]' /><div class="img-title">Show an Image of Photoshop Layers</div></div></p><p>going back to the text rendering problem. What we want to achieve is applying a texture map that contains the text on top of a background. it fits the description of the interpolative blending. let's see how will the result look like.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="placeholder.jpg" alt="Show an Example of Black Edge" sources='[]' /><div class="img-title">Show an Example of Black Edge</div></div></p><p>As we can see, there is a dark edge around the characters, whereas what we want is a pure white text on top of the red background. What causes the dark edges? this is a very common artifact you will see when dealing with alpha blending together with interpolation.</p><p>in our example, we configured the texture sampler to use linear interpolation:</p><pre><code class="language-javascript code-block">        const sampler = device.createSampler({
            addressModeU: 'repeat',
            addressModeV: 'repeat',
            magFilter: 'linear',
            minFilter: 'linear',
            mipmapFilter: 'linear',
        });</code></pre><p>this is required for achieve anti-aliasing, but it introduced another problem. remember that when we generate the text texture, we cleared the canvas with <code>ctx.clearRect(0, 0, width, height);</code>. This function clears the canvas with the transparent black color <code>(0,0,0,0)</code>. whereas when drawing the text, we use the opaque white color <code>(1,1,1,1)</code>. When the GPU performs texture sampling with linear interpolation, any sample position in between the transparent black and a opaque white pixels can be a gray pixel, for example <code>(0.5,0.5,0.5,0.5)</code>, especially near the edge of the text. But this is not what we want. we want the text gradually transit to the background, we don't want to alter the text's color.</p><p>this is a very common issue. Another situation, not as obvious as the above case, is when combining mipmapping and a semi-transparent texture. because mipmapping does linear interpolation between image layers too. One way to solve this problem is using the same text color for the background, only set the alpha channel to zero. This way, interpolation won't change the text color.</p><p>A more elegant way of solving this problem is doing premultiplied alpha blending. premultiplied color means all color values have been multiplied by the alpha value. Assuming an original color is <code>(1.0,1.0,1.0,0.5)</code>, the premultiplied version of the same color is <code>(0.5,0.5,0.5,0.5)</code>. Hence if a premultiplied color is <code>(0,0,0,0)</code>, we can't interpret it as black anymore, because all RGB colors in its premultiplied version become <code>(0,0,0)</code> if the alpha channel is zero.</p><p>To fix the above artifact, we treat the text texture map as premultipled. hence the background color <code>(0,0,0,0)</code> can be interpreted as transparent white. We need to use a different blending formula this time. since the foreground color is premultiplied, we don't need to multiply the alpha channel anymore. we therefore use one this time for the source factor.</p><p class="katex-display-counter"><code class="language-math math-block"> C_s + (1-A_s) * C_d = C</code></p><p>Now, let's look at the result:</p>
        </article>
    </div>
    <!-- The Modal -->
    <div id="img-modal" class="modal">
        <!-- The Close Button -->
        <span class="close" id="img-close">&times;</span>
        <!-- Modal Content (The Image) -->
        <img class="modal-content" id="img01">

        <!-- Modal Caption (Image Text) -->
        <div id="caption"></div>
    </div>
    <script>
        function openImage(img) {
            let modal = document.getElementById("img-modal");
            let modalImg = document.getElementById("img01");
            modal.style.display = "block";
            if (img.getAttribute("original_src")) {
                modalImg.src = img.getAttribute("original_src");
            } else {
                modalImg.src = img.src;
            }
            let captionText = document.getElementById("caption");

            captionText.innerText = img.alt;

            let sources = JSON.parse(img.getAttribute("sources"));

            for (let i = 0; i < sources.length; ++i) {
                if (sources.length == 1) {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE</a>";
                } else {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE " + (i + 1) + "</a>";
                }
            }
        }
        // Get the <span> element that closes the modal
        var closeButton = document.getElementById("img-close");

        // When the user clicks on <span> (x), close the modal
        closeButton.onclick = function () {
            var modal = document.getElementById("img-modal");
            modal.style.display = "none";
        }
    </script>

<script type="module">
    const macros = {};
    const mathElementsBlock = document.getElementsByClassName("math-block");
    for (let element of mathElementsBlock) {
        katex.render(element.textContent, element, {
            throwOnError: false,
            displayMode: true,
            macros
        });
    }

    const mathElementsInline = document.getElementsByClassName("math-inline");
    for (let element of mathElementsInline) {
        katex.render(element.textContent, element, {
            throwOnError: false,
            macros
        });
    }

        hljs.highlightAll();
        // hljs.initLineNumbersOnLoad();
        const codeBlocks = document.getElementsByClassName("code-block");
        for (let i =0;i<codeBlocks.length;++i) {
            if ( codeBlocks[i].hasAttribute("startnumber")) {
                const startFrom = codeBlocks[i].getAttribute("startnumber");
                hljs.lineNumbersBlock(codeBlocks[i], {startFrom:  parseInt(startFrom, 10)});
            } else {
                hljs.lineNumbersBlock(codeBlocks[i]);
            }
        }

</script>
</body>

</html>