<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <link rel="shortcut icon" type="image/x-icon" href="/webgpuunleashed/favicon.ico">
    <!-- Primary Meta Tags -->
    <title>WebGPU Unleashed: A Practical Tutorial</title>
    <meta name="title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta name="description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://shi-yan.github.io/webgpuunleashed/Basics/implementing_cameras.html" />
    <meta property="og:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="og:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="og:image" content="/webgpuunleashed/meta.png" />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="https://shi-yan.github.io/webgpuunleashed/Basics/implementing_cameras.html" />
    <meta property="twitter:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="twitter:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="twitter:image" content="/webgpuunleashed/meta.png" />

    <link rel="stylesheet" href="/webgpuunleashed/style.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script
        src="https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>


    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/base16/default-dark.min.css"
        integrity="sha512-EF2rc4QyBiRAGUMVm+EjFPBbdVGaN/pwZhtuKyrC/dM+hcwTxI5BsEDUkrMRI77z4VlDAt/qVopePXB5+ZZ8Gw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script src="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js
        "></script>
    <link href="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css
        " rel="stylesheet" />
</head>

<body>
    <div id="menuToggle">
        <input id="menuButton" type="checkbox" />
        <span></span>
        <span></span>
        <span></span>
        <div id="menu-container">
            <ul id="menu">
                <!--<li><a href="#">Home</a></li>
                <li><a href="#">About</a></li>
                <li><a id="test" href="#" onclick="fold(event)">Info</a>
                    <ul class="sub-menu">
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                    </ul>
                </li>
                <li><a href="#">Contact</a></li>
                <li><a href="https://erikterwan.com/" target="_blank">Show me more</a></li>-->
                <li><a href="https://shi-yan.github.io/webgpuunleashed">Home</a></li>
                <li><a href="#" onclick="fold(event)">Intro</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Introduction/the_gpu_driver.html">The GPU Driver</a></li>
                        <li><a href="/webgpuunleashed/Introduction/the_gpu_pipeline.html">The GPU Pipeline</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Basics</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Basics/creating_an_empty_canvas.html">Creating an Empty Canvas</a></li>
                        <li><a href="/webgpuunleashed/Basics/drawing_a_triangle.html">Drawing a Triangle</a></li>
                        <li><a href="/webgpuunleashed/Basics/drawing_a_triangle_with_defined_vertices.html">Drawing a Triangle with Defined Vertices</a></li>
                        <li><a href="/webgpuunleashed/Basics/applying_hardcoded_vertex_colors.html">Applying Hardcoded Vertex Colors</a></li>
                        <li><a href="/webgpuunleashed/Basics/using_different_vertex_colors.html">Using Different Vertex Colors</a></li>
                        <li><a href="/webgpuunleashed/Basics/drawing_a_colored_triangle_with_a_single_buffer.html">Drawing a Colored Triangle with a Single Buffer</a></li>
                        <li><a href="/webgpuunleashed/Basics/understanding_uniforms.html">Understanding Uniforms</a></li>
                        <li><a href="/webgpuunleashed/Basics/working_with_textures.html">Working with Textures</a></li>
                        <li><a href="/webgpuunleashed/Basics/utilizing_transformation_matrices.html">Utilizing Transformation Matrices</a></li>
                        <li><a href="/webgpuunleashed/Basics/implementing_cameras.html">Implementing Cameras</a></li>
                        <li><a href="/webgpuunleashed/Basics/triangle_strips.html">Triangle Strips</a></li>
                        <li><a href="/webgpuunleashed/Basics/front_and_back_face_culling.html">Front and Back Face Culling</a></li>
                        <li><a href="/webgpuunleashed/Basics/depth_testing.html">Depth Testing</a></li>
                        <li><a href="/webgpuunleashed/Basics/index_buffers.html">Index Buffers</a></li>
                        <li><a href="/webgpuunleashed/Basics/loading_3d_models.html">Loading 3D Models</a></li>
                        <li><a href="/webgpuunleashed/Basics/understanding_normals.html">Understanding Normals</a></li>
                        <li><a href="/webgpuunleashed/Basics/lighting.html">Lighting</a></li>
                        <li><a href="/webgpuunleashed/Basics/multi_sample_anti_aliasing.html">Multi-Sample Anti-Aliasing</a></li>
                        <li><a href="/webgpuunleashed/Basics/mipmapping_and_anisotropic_filtering.html">Mipmapping and Anisotropic Filtering</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">2D Techniques</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/2D_Techniques/rendering_to_textures.html">Rendering to Textures</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/orthogonal_cameras.html">Orthogonal Cameras</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/implementing_gaussian_blur.html">Implementing Gaussian Blur</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/video_rendering.html">Video Rendering</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/text_rendering.html">Text Rendering</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/billboarding.html">Billboarding</a></li>
                        <li><a href="/webgpuunleashed/2D_Techniques/implementing_fake_3d.html">Implementing Fake 3D</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Control</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Control/canvas_resizing.html">Canvas Resizing</a></li>
                        <li><a href="/webgpuunleashed/Control/arcball_camera_control.html">Arcball Camera Control</a></li>
                        <li><a href="/webgpuunleashed/Control/object_picking.html">Object Picking</a></li>
                        <li><a href="/webgpuunleashed/Control/saving_images_and_videos.html">Saving Images and Videos</a></li>
                        <li><a href="/webgpuunleashed/Control/using_web_workers.html">Using Web Workers</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Compute</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Compute/prefix_sum.html">Prefix Sum</a></li>
                        <li><a href="/webgpuunleashed/Compute/radix_sort.html">Radix Sort</a></li>
                        <li><a href="/webgpuunleashed/Compute/reaction_diffusion.html">Reaction Diffusion</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Advanced</a>
                    <ul class="sub-menu">
                        <li><a href="/webgpuunleashed/Advanced/stencil_buffer.html">Stencil Buffer</a></li>
                        <li><a href="/webgpuunleashed/Advanced/shadow_mapping.html">Shadow Mapping</a></li>
                        <li><a href="/webgpuunleashed/Advanced/toon_shading.html">Toon Shading</a></li>
                        <li><a href="/webgpuunleashed/Advanced/equirectangular_rendering.html">Equirectangular Rendering</a></li>
                        <li><a href="/webgpuunleashed/Advanced/mega_texture.html">Mega Texture</a></li>
                        <li><a href="/webgpuunleashed/Advanced/transparency_with_depth_peeling.html">Transparency with Depth Peeling</a></li>
                        <li><a href="/webgpuunleashed/Advanced/skeleton_animation.html">Skeleton Animation</a></li>
                        <li><a href="/webgpuunleashed/Advanced/gaussian_splatting.html">Gaussian Splatting</a></li>
                    </ul>
                </li>
                <li><a href="https://shi-yan.github.io/webgpuunleashed/code/code.html" target="_blank">Playground</a></li>
                <li><a href="https://github.com/shi-yan/webgpuunleashed" target="_blank">GitHub Repo</a></li>
            </ul>
        </div>
    </div>

    <div id="article-container">
        <article>
            <h2 >1.9 Implementing Cameras</h2><p>In our exploration of computer graphics, we've primarily focused on rendering 2D objects until now. It's time to venture into the realm of 3D rendering and introduce the concept of a camera into our code. You might be surprised to learn that the camera isn't a built-in feature defined within the GPU pipeline or the WebGPU API standard. Instead, we'll craft our own camera by simulating a pinhole camera using model-view transformations and projection onto our vertices, achieved through matrix multiplications.</p><a href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html#1_09_cameras" target="_blank" class="comment"><svg style="margin-right:10px;vertical-align: middle;" xmlns="http://www.w3.org/2000/svg" height="32"
                    width="32" fill="#dadadb" viewBox="0 -960 960 960"><path d="M189-160q-60 0-102.5-43T42-307q0-9 1-18t3-18l84-336q14-54 57-87.5t98-33.5h390q55 0 98 33.5t57 87.5l84 336q2 9 3.5 18.5T919-306q0 61-43.5 103.5T771-160q-42 0-78-22t-54-60l-28-58q-5-10-15-15t-21-5H385q-11 0-21 5t-15 15l-28 58q-18 38-54 60t-78 22Zm3-80q19 0 34.5-10t23.5-27l28-57q15-31 44-48.5t63-17.5h190q34 0 63 18t45 48l28 57q8 17 23.5 27t34.5 10q28 0 48-18.5t21-46.5q0 1-2-19l-84-335q-7-27-28-44t-49-17H285q-28 0-49.5 17T208-659l-84 335q-2 6-2 18 0 28 20.5 47t49.5 19Zm348-280q17 0 28.5-11.5T580-560q0-17-11.5-28.5T540-600q-17 0-28.5 11.5T500-560q0 17 11.5 28.5T540-520Zm80-80q17 0 28.5-11.5T660-640q0-17-11.5-28.5T620-680q-17 0-28.5 11.5T580-640q0 17 11.5 28.5T620-600Zm0 160q17 0 28.5-11.5T660-480q0-17-11.5-28.5T620-520q-17 0-28.5 11.5T580-480q0 17 11.5 28.5T620-440Zm80-80q17 0 28.5-11.5T740-560q0-17-11.5-28.5T700-600q-17 0-28.5 11.5T660-560q0 17 11.5 28.5T700-520Zm-360 60q13 0 21.5-8.5T370-490v-40h40q13 0 21.5-8.5T440-560q0-13-8.5-21.5T410-590h-40v-40q0-13-8.5-21.5T340-660q-13 0-21.5 8.5T310-630v40h-40q-13 0-21.5 8.5T240-560q0 13 8.5 21.5T270-530h40v40q0 13 8.5 21.5T340-460Zm140-20Z"/></svg>Launch Playground - 1_09_cameras</a><p>Before diving into the camera implementation, let's first examine the coordinate systems used by the graphics pipeline and the methods for converting between them. While not every coordinate system is part of the WebGPU specification, these represent the most common approaches to handling coordinate conversion.</p><h3 >Handedness</h3><p>To understand any coordinate system, we must first grasp the concept of handedness. A 3D coordinate system can be either left-handed or right-handed. Imagine facing the xy plane with the x-axis pointing to the right and the y-axis pointing up. The choice of handedness determines the direction of the z-axis.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_handedness.png" original_src="handedness.png" alt="The Left-Handed Coordinates vs. The Right-Handed Coordinates" sources='[]' /><div class="img-title">The Left-Handed Coordinates vs. The Right-Handed Coordinates</div></div></p><p>In a right-handed system, if you align your right hand's thumb with the positive x direction and your index finger with the positive y direction, your middle finger will point in the positive z direction. Conversely, in a left-handed system, using your left hand in the same manner will indicate the positive z direction.</p><p>To visualize this, picture your computer screen as the xy coordinate plane. In a right-handed system, the z-axis points towards you, while in a left-handed system, it points into the screen.</p><p>The choice of handedness is a convention you establish for your program. While the specific system doesn't matter, understanding the concept is crucial for making sense of the mathematics in your application. The handedness of certain coordinates is determined by the WebGPU specification, while for others, it depends on your chosen math library. In our case, we're using the glMatrix library, which adopts a right-handed system to align with OpenGL conventions.</p><h3 >Local coordinates</h3><p>Most 3D models are created in their own coordinate system, known as local coordinates. For instance, in video game development, a 3D character is typically modeled in a 3D application using its own coordinate system. For convenience, the character might be positioned at the origin in this local space.</p><h3 >World coordinates</h3><p>A single model doesn't create an entire game world. Often, we need to load numerous 3D models and construct a 3D scene from them. In most 3D applications, models are dynamic—you can move, rotate, and scale them within the 3D scene. Consequently, we can't rely solely on each model's local coordinates. We need to transform their coordinate systems into a unified one.</p><p>At this stage, our primary concern is the translation, rotation, and scaling of the models and their relative positions. We can choose any point in 3D space as the world's origin and offset all models accordingly. Regardless of which coordinate system you designate as the world coordinate system, the conversion from a model's local coordinates to world coordinates should be accomplished through a single matrix multiplication. This matrix is called the model matrix. After this conversion, all models in the scene should use the same coordinate system.</p><h3 >View coordinates</h3><p>Our ultimate goal is to project the 3D scene onto a 2D view plane. This projection is calculated relative to the viewpoint, which is the location of the camera. To simplify this process, we convert the coordinate system once more, creating what's known as the view coordinate system.</p><p>In this new system, the camera's position becomes the origin. The y-axis points upward, the x-axis points to the right, and in our right-handed coordinate system, the z-axis points towards the camera. Consequently, the negative z-axis extends into the scene. This transformation allows us to calculate the projection from the camera's perspective more easily.</p><h3 >Projection</h3><p>Projection is the process of transforming our 3D scene onto a 2D plane, and there are two primary types: perspective and orthogonal.</p><p>Perspective projection mimics how we perceive depth in the real world, where objects farther from the viewer appear smaller. This creates a sense of depth and realism in rendered scenes. Orthogonal projection, on the other hand, maintains object size regardless of distance. While less common in realistic rendering, orthogonal projection has valuable applications in technical drawings and certain types of games.</p><p>In this discussion, we'll focus on perspective projection, reserving orthogonal projection for a future exploration. The following image illustrates the key difference between these two projection types:</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_persportho.png" original_src="persportho.png" alt="Perspective Projection (Left) vs. Orthogonal Projection (Right)" sources='[]' /><div class="img-title">Perspective Projection (Left) vs. Orthogonal Projection (Right)</div></div></p><p>To model our camera, we use a simple pinhole model. In this model, the visible volume forms a shape called a frustum - essentially a truncated pyramid. The front face of this frustum can be thought of as our screen or view plane.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_view_frustrum.png" original_src="view_frustrum.png" alt="With a Pin-Hole Camera Model, the Visible Volume Is a Trapezoidal Prism, Called the View Frustum" sources='[]' /><div class="img-title">With a Pin-Hole Camera Model, the Visible Volume Is a Trapezoidal Prism, Called the View Frustum</div></div></p><p>The primary objective of perspective projection is to transform this trapezoidal frustum into a cuboid. In this transformation, both the front and back faces of the frustum are adjusted to the same size. Specifically, after projection, both the front and back planes, as well as the z-range, must fall within the range of <code class="language-math math-inline">[-1, 1]</code>. In other words, our projection deforms the original visible volume into a cube with a side length of 2.</p><p>This resulting cuboid exists in what we call Normalized Device Coordinates (NDC). The NDC system is a standardized 3D space that simplifies the final stages of rendering, regardless of the original scene's scale or the specific projection used.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_viewtondc.png" original_src="viewtondc.png" alt="Projection Converts the View Frustum in the View Coordinates Into Normalized Device Coordinates" sources='[]' /><div class="img-title">Projection Converts the View Frustum in the View Coordinates Into Normalized Device Coordinates</div></div></p><p>Normalized Device Coordinates (NDC) represent a standardized 3D space enclosed by the points <code class="language-math math-inline">(-1,-1,-1)</code> and <code class="language-math math-inline">(1,1,1)</code>. The transformation from view coordinates to NDC, accomplished through the projection process, is illustrated in the image above. It's crucial to note a significant change that occurs during this transformation: while the view coordinates are right-handed, the resulting NDC system becomes left-handed, with the positive z-axis now pointing away from the camera.</p><p>This shift in handedness is a critical point of distinction. Prior to NDC, all the coordinate systems we've discussed are not strictly defined by the WebGPU specification, allowing developers the flexibility to choose their preferred handedness. However, the NDC system is explicitly defined in the WebGPU spec, requiring strict adherence. The projection process facilitates this transition from a right-handed to a left-handed system by essentially flipping the z-axis, an operation conceptually similar to mirroring.</p><p>Like other transformations we've encountered, projection can be achieved through a single matrix multiplication. However, deriving this projection matrix is not as straightforward as it might seem at first glance. To understand its construction, let's approach it step by step.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_projection.png" original_src="projection.png" alt="Project of a Point E in the View Coordinates to the Near Plane" sources='[]' /><div class="img-title">Project of a Point E in the View Coordinates to the Near Plane</div></div></p><p>Let's begin by focusing on the x-axis. We'll project point <code>e</code> onto the near plane, resulting in point <code>p</code>. The x and y coordinates of <code>p</code> must then be mapped to the range [-1, 1] for use in NDC.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_topviewproj.png" original_src="topviewproj.png" alt="Top View of the View Coordinates" sources='[]' /><div class="img-title">Top View of the View Coordinates</div></div></p><p>We can establish the following relationship:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
  \frac{x_p}{x_e} &= \frac{-n}{z_e} \\
  x_p &= \frac{-n*x_e}{z_e}
\end{aligned}</code></p><p>Here, <code class="language-math math-inline">n</code> represents the focal length (or the near plane distance) of our pinhole camera model. The y-coordinate follows an identical relationship:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
  \frac{y_p}{y_e} &= \frac{-n}{z_e} \\
  y_p &= \frac{-n*y_e}{z_e}
\end{aligned}</code></p><p>While <code class="language-math math-inline">(x_p, y_p)</code> gives us the coordinates of the projected point <code>p</code> on the near plane, these are not yet the NDC coordinates. To comply with NDC requirements, we need to map these coordinates to the range <code class="language-math math-inline">[-1, 1]</code>. This mapping is a linear transformation:</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_p2ndcmapping.png" original_src="p2ndcmapping.png" alt="Linear Relationship Between the Coordinates of P to Its NDC" sources='[]' /><div class="img-title">Linear Relationship Between the Coordinates of P to Its NDC</div></div></p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
    x_{ndc} &= \frac{1--1}{r-l}*x_p + \beta_{1} \\
    y_{ndc} &= \frac{1--1}{t-b}*y_p + \beta_{2}
\end{aligned}</code></p><p>Here, <code class="language-math math-inline">r</code> and <code class="language-math math-inline">l</code> represent the right and left boundaries of the near plane, while <code class="language-math math-inline">t</code> and <code class="language-math math-inline">b</code> denote the top and bottom boundaries. When <code>p</code> is at the center of the near plane (i.e., at <code class="language-math math-inline">(\frac{r+l}{2},\frac{t+b}{2})</code>), <code class="language-math math-inline">(x_{ndc}, y_{ndc})</code> should also be at the center (0, 0). Using this relationship, we can determine <code class="language-math math-inline">\beta_{1}</code> and <code class="language-math math-inline">\beta_{2}</code>:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
    \beta_{1} &= - \frac{1--1}{r-l}*\frac{r+l}{2} = - \frac{r+l}{r-l} \\
    \beta_{2} &= - \frac{1--1}{t-b}*\frac{t+b}{2} = - \frac{t+b}{t-b}
\end{aligned}</code></p><p>Thus, our equations become:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
    x_{ndc} &= \frac{1--1}{r-l}*x_p - \frac{r+l}{r-l} \\
            &= \frac{1--1}{r-l}* \frac{-n*x_e}{z_e} - \frac{r+l}{r-l} \\
            &= \frac{-2n*x_e}{z_e*(r-l)} - \frac{r+l}{r-l} \\
            &= - \frac{\frac{2n*x_e}{r-l} + \frac{r+l}{r-l}}{z_e} \\
    y_{ndc} &= \frac{1--1}{t-b}*y_p - \frac{t+b}{t-b} \\
            &= \frac{1--1}{t-b}* \frac{-n*y_e}{z_e} - \frac{t+b}{t-b} \\
            &= \frac{-2n*y_e}{z_e*(t-b)} - \frac{t+b}{t-b} \\
            &= - \frac{\frac{2n*y_e}{t-b} + \frac{t+b}{t-b}}{z_e}
\end{aligned}</code></p><p>Now, let's express this transformation in matrix form:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{pmatrix}
\frac{2n}{r-l} & 0 & \frac{r+l}{r-l} & 0 \\
0 & \frac{2n}{t-b} & \frac{t+b}{t-b} & 0 \\
0 & 0 & A & B \\
0 & 0 & -1 & 0
\end{pmatrix} \times
\begin{pmatrix}
x_e \\ 
y_e \\ 
z_e \\
1
\end{pmatrix}</code></p><p>Note that to calculate <code class="language-math math-inline">x_{ndc}</code> and <code class="language-math math-inline">y_{ndc}</code>, we need to divide by <code class="language-math math-inline">-z_e</code> as the final step. We achieve this by utilizing the homogeneous coordinates' scaling factor <code class="language-math math-inline">w_{ndc} = -z_e</code>. This approach allows us to incorporate the division into our matrix multiplication, which is crucial since direct element-wise division isn't possible in matrix multiplication.</p><p>The final piece of our projection puzzle is mapping <code class="language-math math-inline">z_e</code> to <code class="language-math math-inline">z_{ndc}</code>. Unlike the linear mapping from <code class="language-math math-inline">x_e</code> to <code class="language-math math-inline">x_p</code>, the relationship between <code class="language-math math-inline">z_e</code> and <code class="language-math math-inline">z_p</code> is non-linear. Although we could find a linear mapping between them, we opt for a different approach to accommodate our matrix multiplication format. Let's derive the values for <code class="language-math math-inline">A</code> and <code class="language-math math-inline">B</code> in our projection matrix:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
z_{ndc} &= \frac{A*z_e + B}{-z_e} \\
\frac{-An+B}{n} &= -1 \\
\frac{-Af+B}{f} &= 1
\end{aligned}</code></p><p>Here, <code class="language-math math-inline">-n</code> and <code class="language-math math-inline">-f</code> represent the near and far plane distances, respectively. Solving for <code class="language-math math-inline">A</code> and <code class="language-math math-inline">B</code>:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{aligned}
A &= - \frac{f+n}{f-n}\\
B &= - \frac{2fn}{f-n} \\
z_{ndc} &= \frac{- \frac{f+n}{f-n}*z_e - \frac{2fn}{f-n}}{-z_e}
\end{aligned}</code></p><p>Now we can express the complete projection calculation as a single matrix multiplication:</p><p class="katex-display-counter"><code class="language-math math-block">\begin{pmatrix}
\frac{2n}{r-l} & 0 & \frac{r+l}{r-l} & 0 \\
0 & \frac{2n}{t-b} & \frac{t+b}{t-b} & 0 \\
0 & 0 & - \frac{f+n}{f-n} & - \frac{2fn}{f-n} \\
0 & 0 & -1 & 0
\end{pmatrix} \times
\begin{pmatrix}
x_e \\ 
y_e \\ 
z_e \\
1
\end{pmatrix}</code></p><p>It's important to note that the mapping between <code class="language-math math-inline">z_e</code> and <code class="language-math math-inline">z_{ndc}</code> is non-linear. To better understand this relationship, let's visualize it with a plot, assuming <code class="language-math math-inline">f = 50</code> and <code class="language-math math-inline">n = 10</code>:</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_ze2zndcmapping.png" original_src="ze2zndcmapping.png" alt="Plot the Mapping From Ze to Zndc" sources='[]' /><div class="img-title">Plot the Mapping From Ze to Zndc</div></div></p><p>This graph reveals an interesting property: as we move from the far plane to the near plane, the rate of change in <code class="language-math math-inline">z_{ndc}</code> increases. In practice, <code class="language-math math-inline">z_{ndc}</code> serves as the depth value used in depth testing, determining which fragments are closest to the camera and should therefore occlude those behind them.</p><p>The non-linear nature of this mapping has a significant implication: fragments closer to the camera benefit from greater depth accuracy compared to those further away. This characteristic aligns well with human perception and the needs of most 3D applications, where precise depth discrimination is often more critical for nearby objects.</p><p>From a development perspective, our primary task is to convert coordinates from local space to Normalized Device Coordinates (NDC). The subsequent steps from NDC to 2D fragments are handled automatically by the GPU. For a comprehensive understanding of WebGPU's coordinate systems, I recommend reviewing the <a class="link" href="https://www.w3.org/TR/webgpu/#coordinate-systems" target="_blank">relevant section in the WebGPU specification</a>.</p><p>Let's briefly outline the remaining steps in the rendering pipeline:</p><ol><li><p>Conversion to Clip Space: The GPU transforms NDC to clip space coordinates using the formula <code class="language-math math-inline">(\frac{x_{ndc}}{w_{ndc}},\frac{y_{ndc}}{w_{ndc}},\frac{z_{ndc}}{w_{ndc}})</code>. This step achieves the division by <code class="language-math math-inline">-z_{ndc}</code> that we previously discussed.</p></li><li><p>Viewport Transformation: Next, clip coordinates are converted to viewport coordinates. This is where our viewport settings come into play. In viewport space:</p></li></ol><ul><li><p>The x-axis points right</p></li><li><p>The y-axis points down</p></li><li><p>The coordinate range matches the viewport's width and height, as specified in the setViewport function</p></li><li><p>The depth is mapped from <code class="language-math math-inline">[-1,1]</code> to <code class="language-math math-inline">[minDepth, maxDepth]</code>, typically <code class="language-math math-inline">[0,1]</code></p></li></ul><p>This image illustrates the mapping between NDC and viewport coordinates:</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_ndc2viewport.png" original_src="ndc2viewport.png" alt="Mapping From NDC (Left) to the Viewport Coordinates (Right), With the Viewport Configured as (640,480,0,1)" sources='[]' /><div class="img-title">Mapping From NDC (Left) to the Viewport Coordinates (Right), With the Viewport Configured as (640,480,0,1)</div></div></p><p>It's important to note that after rasterization, fragment coordinates are in viewport coordinates. This can be counterintuitive, as we output clip coordinates from the vertex shader but receive viewport coordinates in the fragment shader, despite these variables sharing the same name. This distinction becomes crucial when implementing advanced effects like shadows in future chapters.</p><p>With this theoretical foundation, we can now implement a camera in WebGPU. Essentially, a camera is represented by two matrices:</p><ol><li><p>A view matrix, determined by the camera's position and orientation</p></li><li><p>A projection matrix, based on the camera's aspect ratio and focal length</p></li></ol><p>The glMatrix library provides convenient functions to generate these matrices efficiently. To apply these matrices to vertices, we use the same technique we've employed previously: passing the matrices as uniforms and performing matrix multiplication on vertex positions in the shader.</p><p>Let's examine the implementation details in the code:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=12>@group(0) @binding(0)
var&lt;uniform&gt; transform: mat4x4&lt;f32&gt;;
@group(0) @binding(1)
var&lt;uniform&gt; projection: mat4x4&lt;f32&gt;;
</pre></code><div class="code-fragments-separator">• • •</div><pre><code class="language-javascript code-block" startNumber=20>@vertex
fn vs_main(
    @location(0) inPos: vec3&lt;f32&gt;,
    @location(1) inTexCoords: vec2&lt;f32&gt;
) -&gt; VertexOutput {
    var out: VertexOutput;
    out.clip_position = projection * transform * vec4&lt;f32&gt;(inPos, 1.0);
    out.tex_coords = inTexCoords;
    return out;
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=11:14,19:28#1_09_cameras">1_09_cameras/index.html:12-29 The Vertex Shader</a></div></div><p>The vertex shader undergoes minimal changes in this implementation. We've added a projection matrix alongside the existing transformation matrix. The transformation matrix repositions objects in front of the camera, converting coordinates from local space to view space. The projection matrix then applies the final transformation, projecting the view space to NDC. Both transformations are applied through simple matrix multiplications.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=115>let transformationMatrix = glMatrix.mat4.lookAt(glMatrix.mat4.create(), 
glMatrix.vec3.fromValues(100, 100, 100), glMatrix.vec3.fromValues(0,0,0), glMatrix.vec3.fromValues(0.0, 0.0, 1.0));

let projectionMatrix = glMatrix.mat4.perspective(glMatrix.mat4.create(), 
1.4, 640.0 / 480.0, 0.1, 1000.0);
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=114:118#1_09_cameras">1_09_cameras/index.html:115-119 Generate Transformation and Projection Matrices Using glMatrix</a></div></div><p>What's next is new to us: using glMatrix to generate both the transformation (view) matrix and the projection matrix. For simplicity, we assume the object is already in world coordinates, focusing on the conversion to view coordinates using the view matrix.</p><p>To generate the view matrix, we use the <code>lookAt</code> function, which takes three parameters:</p><ul><li><p>Position of the viewer</p></li><li><p>Point the viewer is looking at</p></li><li><p>Up vector of the camera</p></li></ul><p>Note that while the up vector should ideally be orthogonal to the viewing direction, glMatrix will automatically adjust non-orthogonal vectors to ensure correct camera orientation.</p><p>For the projection matrix, we use the <code>perspective</code> function, which requires:</p><ul><li><p>Vertical field of view in radians (<code>fovy</code>), related to focal length</p></li><li><p>Aspect ratio, typically viewport width/height</p></li><li><p>Near bound of the frustum</p></li><li><p>Far bound of the frustum</p></li></ul><p>One of the advantages of using glMatrix is that it generates matrices as <code>Float32Array</code> objects, which can be directly loaded into GPU buffers:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=120>let transformationMatrixUniformBuffer = createGPUBuffer(device, transformationMatrix, GPUBufferUsage.UNIFORM);

let projectionMatrixUniformBuffer = createGPUBuffer(device, projectionMatrix, GPUBufferUsage.UNIFORM);

let uniformBindGroupLayout = device.createBindGroupLayout({
    entries: [
        {
            binding: 0,
            visibility: GPUShaderStage.VERTEX,
            buffer: {}
        },
        {
            binding: 1,
            visibility: GPUShaderStage.VERTEX,
            buffer: {}
        },
        {
            binding: 2,
            visibility: GPUShaderStage.FRAGMENT,
            texture: {}
        },
        {
            binding: 3,
            visibility: GPUShaderStage.FRAGMENT,
            sampler: {}
        }
    ]
});

let uniformBindGroup = device.createBindGroup({
    layout: uniformBindGroupLayout,
    entries: [
        {
            binding: 0,
            resource: {
                buffer: transformationMatrixUniformBuffer
            }
        },
        {
            binding: 1,
            resource: {
                buffer: projectionMatrixUniformBuffer
            }
        },
        {
            binding: 2,
            resource: texture.createView()
        },
        {
            binding: 3,
            resource:
                sampler
        }
    ]
});
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=119:173#1_09_cameras">1_09_cameras/index.html:120-174 Setup Uniform Buffers</a></div></div><p>The uniform setup remains largely unchanged from previous examples. While the rendering result – a textured triangle viewed from an angle – might seem unexciting, this approach allows for incremental learning and provides a foundation for more complex implementations.</p><p>To challenge yourself and better understand the camera system, consider modifying this sample to create an animation where the camera rotates around the triangle. This exercise would involve:</p><ul><li><p>Updating the camera position in each frame</p></li><li><p>Recalculating the view matrix</p></li><li><p>Updating the uniform buffer with the new matrix</p></li><li><p>Requesting a new frame for continuous animation</p></li></ul><p>By implementing this animation, you'll gain practical experience in manipulating 3D camera systems and create a more dynamic and engaging visualization of the 3D space.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_camera.png" original_src="camera.png" alt="The Same Textured Triangle Is Viewed in an Angle" sources='[]' /><div class="img-title">The Same Textured Triangle Is Viewed in an Angle</div></div></p>
        </article>

        <div class="older_newer_link_section">
            <div class="older_newer_link_left">
                <p>
                    <svg xmlns="http://www.w3.org/2000/svg" height="12" width="11" fill="#dadadb"
                        viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
                        <path
                            d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" />
                    </svg>
                    PREV POST
                </p>
                <p>
                    <a class="older_newer_link" href="/webgpuunleashed/Basics/utilizing_transformation_matrices.html">Utilizing Transformation Matrices</a>
                </p>
            </div>

            <div class="older_newer_link_right">
                <p>
                    NEXT POST
                    <svg xmlns="http://www.w3.org/2000/svg" height="12" width="11" fill="#dadadb"
                        viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
                        <path
                            d="M438.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-160-160c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L338.8 224 32 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l306.7 0L233.4 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l160-160z" />
                    </svg>
                </p>
                <p>
                    <a class="older_newer_link" href="/webgpuunleashed/Basics/triangle_strips.html">Triangle Strips</a>
                </p>
            </div>
        </div>

        <a href="https://github.com/shi-yan/WebGPUUnleashed/discussions" target="_blank" class="comment"><svg
            style="margin-right:10px;vertical-align: middle;" xmlns="http://www.w3.org/2000/svg" height="32"
            width="32" fill="#dadadb"
            viewBox="0 0 480 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
            <path
                d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z" />
        </svg> Leave a Comment on Github</a>
    </div>
    <!-- The Modal -->
    <div id="img-modal" class="modal">
        <!-- The Close Button -->
        <span class="close" id="img-close">&times;</span>
        <!-- Modal Content (The Image) -->
        <img class="modal-content" id="img01">

        <!-- Modal Caption (Image Text) -->
        <div id="caption"></div>
    </div>
    <script>
        function fold(e) {
            const sub = e.currentTarget.parentElement.getElementsByTagName("ul")[0];
            console.log("sub", e.currentTarget, sub);
            if (sub.style.display === "block") {
                sub.style.display = "none";
            } else {
                sub.style.display = "block";
            }
        }
    
        window.addEventListener('click', (e) => {
           // const sub = e.currentTarget.parentElement.getElementsByTagName("ul")[0];
            document.getElementById("menuButton").checked = false;
        });
    
        document.getElementById("menu-container").addEventListener('click',(event) => {
            event.stopPropagation();
        });

        document.getElementById("menuButton").addEventListener('click', (event) => {
            event.stopPropagation();
        });
       
        function openImage(img) {
            let modal = document.getElementById("img-modal");
            let modalImg = document.getElementById("img01");
            modal.style.display = "block";
            if (img.getAttribute("original_src")) {
                modalImg.src = img.getAttribute("original_src");
            } else {
                modalImg.src = img.src;
            }
            let captionText = document.getElementById("caption");

            captionText.innerText = img.alt;

            let sources = JSON.parse(img.getAttribute("sources"));

            for (let i = 0; i < sources.length; ++i) {
                if (sources.length == 1) {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE</a>";
                } else {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE " + (i + 1) + "</a>";
                }
            }
        }
        // Get the <span> element that closes the modal
        var closeButton = document.getElementById("img-close");

        // When the user clicks on <span> (x), close the modal
        closeButton.onclick = function () {
            var modal = document.getElementById("img-modal");
            modal.style.display = "none";
        }
    </script>

    <script type="module">
        const macros = {};
        const mathElementsBlock = document.getElementsByClassName("math-block");
        for (let element of mathElementsBlock) {
            katex.render(element.textContent, element, {
                throwOnError: false,
                displayMode: true,
                macros
            });
        }

        const mathElementsInline = document.getElementsByClassName("math-inline");
        for (let element of mathElementsInline) {
            katex.render(element.textContent, element, {
                throwOnError: false,
                macros
            });
        }

        hljs.highlightAll();
        // hljs.initLineNumbersOnLoad();
        const codeBlocks = document.getElementsByClassName("code-block");
        for (let i = 0; i < codeBlocks.length; ++i) {
            if (codeBlocks[i].hasAttribute("startnumber")) {
                const startFrom = codeBlocks[i].getAttribute("startnumber");
                hljs.lineNumbersBlock(codeBlocks[i], { startFrom: parseInt(startFrom, 10) });
            } else {
                hljs.lineNumbersBlock(codeBlocks[i]);
            }
        }

    </script>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-G278P1YSJ6"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag() { dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'G-G278P1YSJ6');
</script>
</body>

</html>