<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <link rel="shortcut icon" type="image/x-icon" href="/WebGPUUnleashed/favicon.ico">
    <!-- Primary Meta Tags -->
    <title>WebGPU Unleashed: A Practical Tutorial</title>
    <meta name="title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta name="description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://shi-yan.github.io/WebGPUUnleashed/Control/object_picking.html" />
    <meta property="og:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="og:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="og:image" content="/WebGPUUnleashed/meta.png" />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="https://shi-yan.github.io/WebGPUUnleashed/Control/object_picking.html" />
    <meta property="twitter:title" content="WebGPU Unleashed: A Practical Tutorial" />
    <meta property="twitter:description" content="WebGPU Unleashed, your ticket to the dynamic world of graphics programming. Dive in and discover the magic of creating stunning visuals from scratch, mastering the art of real-time graphics, and unlocking the power of WebGPU - all in one captivating tutorial." />
    <meta property="twitter:image" content="/WebGPUUnleashed/meta.png" />

    <link rel="stylesheet" href="/WebGPUUnleashed/style.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script
        src="https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>


    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/base16/default-dark.min.css"
        integrity="sha512-EF2rc4QyBiRAGUMVm+EjFPBbdVGaN/pwZhtuKyrC/dM+hcwTxI5BsEDUkrMRI77z4VlDAt/qVopePXB5+ZZ8Gw=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script src="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js
        "></script>
    <link href="
        https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css
        " rel="stylesheet" />
</head>

<body>
    <div id="menuToggle">
        <input id="menuButton" type="checkbox" />
        <span></span>
        <span></span>
        <span></span>
        <div id="menu-container">
            <ul id="menu">
                <!--<li><a href="#">Home</a></li>
                <li><a href="#">About</a></li>
                <li><a id="test" href="#" onclick="fold(event)">Info</a>
                    <ul class="sub-menu">
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                        <li><a href="#">test menu;</a></li>
                    </ul>
                </li>
                <li><a href="#">Contact</a></li>
                <li><a href="https://erikterwan.com/" target="_blank">Show me more</a></li>-->
                <li><a href="https://shi-yan.github.io/WebGPUUnleashed">Home</a></li>
                <li><a href="#" onclick="fold(event)">Intro</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Introduction/the_gpu_driver.html">The GPU Driver</a></li>
                        <li><a href="/WebGPUUnleashed/Introduction/the_gpu_pipeline.html">The GPU Pipeline</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Basics</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Basics/creating_an_empty_canvas.html">Creating an Empty Canvas</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/drawing_a_triangle.html">Drawing a Triangle</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/drawing_a_triangle_with_defined_vertices.html">Drawing a Triangle with Defined Vertices</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/applying_hardcoded_vertex_colors.html">Applying Hardcoded Vertex Colors</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/using_different_vertex_colors.html">Using Different Vertex Colors</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/drawing_a_colored_triangle_with_a_single_buffer.html">Drawing a Colored Triangle with a Single Buffer</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/understanding_uniforms.html">Understanding Uniforms</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/working_with_textures.html">Working with Textures</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/utilizing_transformation_matrices.html">Utilizing Transformation Matrices</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/implementing_cameras.html">Implementing Cameras</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/triangle_strips.html">Triangle Strips</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/front_and_back_face_culling.html">Front and Back Face Culling</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/depth_testing.html">Depth Testing</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/index_buffers.html">Index Buffers</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/loading_3d_models.html">Loading 3D Models</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/understanding_normals.html">Understanding Normals</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/lighting.html">Lighting</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/multi_sample_anti_aliasing.html">Multi-Sample Anti-Aliasing</a></li>
                        <li><a href="/WebGPUUnleashed/Basics/mipmapping_and_anisotropic_filtering.html">Mipmapping and Anisotropic Filtering</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">2D Techniques</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/2D_Techniques/rendering_to_textures.html">Rendering to Textures</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/orthogonal_cameras.html">Orthogonal Cameras</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/implementing_gaussian_blur.html">Implementing Gaussian Blur</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/video_rendering.html">Video Rendering</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/text_rendering.html">Text Rendering</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/billboarding.html">Billboarding</a></li>
                        <li><a href="/WebGPUUnleashed/2D_Techniques/implementing_fake_3d.html">Implementing Fake 3D</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Control</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Control/canvas_resizing.html">Canvas Resizing</a></li>
                        <li><a href="/WebGPUUnleashed/Control/arcball_camera_control.html">Arcball Camera Control</a></li>
                        <li><a href="/WebGPUUnleashed/Control/object_picking.html">Object Picking</a></li>
                        <li><a href="/WebGPUUnleashed/Control/saving_images_and_videos.html">Saving Images and Videos</a></li>
                        <li><a href="/WebGPUUnleashed/Control/using_web_workers.html">Using Web Workers</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Compute</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Compute/prefix_sum.html">Prefix Sum</a></li>
                        <li><a href="/WebGPUUnleashed/Compute/radix_sort.html">Radix Sort</a></li>
                        <li><a href="/WebGPUUnleashed/Compute/reaction_diffusion.html">Reaction Diffusion</a></li>
                    </ul>
                </li>
                <li><a href="#" onclick="fold(event)">Advanced</a>
                    <ul class="sub-menu">
                        <li><a href="/WebGPUUnleashed/Advanced/stencil_buffer.html">Stencil Buffer</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/shadow_mapping.html">Shadow Mapping</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/toon_shading.html">Toon Shading</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/equirectangular_rendering.html">Equirectangular Rendering</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/mega_texture.html">Mega Texture</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/transparency_with_depth_peeling.html">Transparency with Depth Peeling</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/skeleton_animation.html">Skeleton Animation</a></li>
                        <li><a href="/WebGPUUnleashed/Advanced/gaussian_splatting.html">Gaussian Splatting</a></li>
                    </ul>
                </li>
                <li><a href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html" target="_blank">Playground</a></li>
                <li><a href="https://github.com/shi-yan/WebGPUUnleashed" target="_blank">GitHub Repo</a></li>
            </ul>
        </div>
    </div>

    <div id="article-container">
        <article>
            <h2 >3.2 Object Picking</h2><p>Another important form of interaction in 3D graphics is object picking or selection. For example, in an RTS game, we use the mouse to select the units we want to control.</p><h3 >Ray casting</h3><a href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html#3_02_1_picking_ray_casting" target="_blank" class="comment"><svg style="margin-right:10px;vertical-align: middle;" xmlns="http://www.w3.org/2000/svg" height="32"
                    width="32" fill="#dadadb" viewBox="0 -960 960 960"><path d="M189-160q-60 0-102.5-43T42-307q0-9 1-18t3-18l84-336q14-54 57-87.5t98-33.5h390q55 0 98 33.5t57 87.5l84 336q2 9 3.5 18.5T919-306q0 61-43.5 103.5T771-160q-42 0-78-22t-54-60l-28-58q-5-10-15-15t-21-5H385q-11 0-21 5t-15 15l-28 58q-18 38-54 60t-78 22Zm3-80q19 0 34.5-10t23.5-27l28-57q15-31 44-48.5t63-17.5h190q34 0 63 18t45 48l28 57q8 17 23.5 27t34.5 10q28 0 48-18.5t21-46.5q0 1-2-19l-84-335q-7-27-28-44t-49-17H285q-28 0-49.5 17T208-659l-84 335q-2 6-2 18 0 28 20.5 47t49.5 19Zm348-280q17 0 28.5-11.5T580-560q0-17-11.5-28.5T540-600q-17 0-28.5 11.5T500-560q0 17 11.5 28.5T540-520Zm80-80q17 0 28.5-11.5T660-640q0-17-11.5-28.5T620-680q-17 0-28.5 11.5T580-640q0 17 11.5 28.5T620-600Zm0 160q17 0 28.5-11.5T660-480q0-17-11.5-28.5T620-520q-17 0-28.5 11.5T580-480q0 17 11.5 28.5T620-440Zm80-80q17 0 28.5-11.5T740-560q0-17-11.5-28.5T700-600q-17 0-28.5 11.5T660-560q0 17 11.5 28.5T700-520Zm-360 60q13 0 21.5-8.5T370-490v-40h40q13 0 21.5-8.5T440-560q0-13-8.5-21.5T410-590h-40v-40q0-13-8.5-21.5T340-660q-13 0-21.5 8.5T310-630v40h-40q-13 0-21.5 8.5T240-560q0 13 8.5 21.5T270-530h40v40q0 13 8.5 21.5T340-460Zm140-20Z"/></svg>Launch Playground - 3_02_1_picking_ray_casting</a><p>There are two common ways to implement picking. We will look at both in this tutorial. The first method is called ray casting, and its principle is straightforward. Recall that by applying a projection matrix, we can project a 3D point onto the screen plane. Ray casting simply reverses this process: given a 2D position on the screen plane (our mouse cursor position), we obtain a ray by using the projection matrix. This ray will overlap the 2D point if projected. We then use that ray to test against objects that might intersect with it. If an intersection occurs, we select the object of interest.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_raycasting.png" original_src="raycasting.png" alt="Object Picking by Raycasting" sources='[]' /><div class="img-title">Object Picking by Raycasting</div></div></p><p>Precise ray-object intersection can be challenging to compute if the object has a complex shape, such as a teapot. Usually, we use an overlapping proxy geometry for the calculation. For example, a bounding box or a bounding sphere. Typically, the ray intersection can be efficiently checked against the proxy geometry using a simple formula. In this tutorial, we will be using proxy spheres.</p><p>In this demo, we will render 16 teapots forming a ring using the instancing technique. Each teapot is enclosed by a proxy sphere. We render the proxy sphere for visualization purposes. Ray casting is primarily calculated by the CPU code in JavaScript, so I will omit most of the explanation regarding rendering. Please refer to the sample code for details. Here, I want to focus on the scene setup.</p><p>The choice of spheres as the proxy geometry is mainly due to the ease of calculating sphere-ray intersections compared to other proxy geometries. However, using spheres is not the most accurate option.</p><p>The first part involves constructing three rings to represent the proxy sphere, similar to what we created in the previous chapter. The three rings are perpendicular to each other because we want to use them to represent the silhouette of the proxy sphere.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=177>const teapotCenter = glMatrix.vec4.fromValues(center[0], center[1], center[2], 1.0);

console.log("teapot center", teapotCenter);

this.ringPositionBuffer = [];

for (let i = 0; i &lt; 16; ++i) {
    const angle = 2.0 * Math.PI * i / 16.0;
    const x = Math.cos(angle) * radius;
    const y = Math.sin(angle) * radius;

    this.ringPositionBuffer.push(x + center[0]);
    this.ringPositionBuffer.push(y + center[1]);
    this.ringPositionBuffer.push(0.0 + center[2]);
}

this.ringPositionBuffer = createGPUBuffer(device, new Float32Array(this.ringPositionBuffer), GPUBufferUsage.VERTEX);

this.ringPositionBuffer2 = [];
for (let i = 0; i &lt; 16; ++i) {
    const angle = 2.0 * Math.PI * i / 16.0;
    const x = Math.cos(angle) * radius;
    const z = Math.sin(angle) * radius;

    this.ringPositionBuffer2.push(x + center[0]);
    this.ringPositionBuffer2.push(0.0 + center[1]);
    this.ringPositionBuffer2.push(z + center[2]);
}

this.ringPositionBuffer2 = createGPUBuffer(device, new Float32Array(this.ringPositionBuffer2), GPUBufferUsage.VERTEX);


this.ringPositionBuffer3 = [];
for (let i = 0; i &lt; 16; ++i) {
    const angle = 2.0 * Math.PI * i / 16.0;
    const y = Math.cos(angle) * radius;
    const z = Math.sin(angle) * radius;

    this.ringPositionBuffer3.push(0.0 + center[0]);
    this.ringPositionBuffer3.push(y + center[1]);
    this.ringPositionBuffer3.push(z + center[2]);
}
this.ringPositionBuffer3 = createGPUBuffer(device, new Float32Array(this.ringPositionBuffer3), GPUBufferUsage.VERTEX);
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=176:218#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:177-219 Create 3 Perpendicular Rings Around the Teapot to Visualize the Proxy Sphere</a></div></div><p>Here, we create three position buffers, each containing the vertices of a ring centered at the teapot's center. Next, we will set up individual rotation and translation for each teapot instance:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=220>for (let i = 0; i &lt; this.instanceCount; ++i) {

    const angle = 2.0 * Math.PI * i / this.instanceCount;

    let translation = glMatrix.mat4.fromTranslation(glMatrix.mat4.create(),
        glMatrix.vec3.fromValues(Math.cos(angle) * circleRadius,
            Math.sin(angle) * circleRadius, 0));
    let rotation = glMatrix.mat4.fromRotation(glMatrix.mat4.create(), Math.PI * 0.5 + angle, glMatrix.vec3.fromValues(0.0, 0.0, 1.0));

    const modelViewMatrix = glMatrix.mat4.multiply(glMatrix.mat4.create(), translation, rotation);

    transformationMats.set(modelViewMatrix, i * 16);

    let modelViewMatrixInverse = glMatrix.mat4.invert(glMatrix.mat4.create(), modelViewMatrix);

    let normalMatrix = glMatrix.mat4.transpose(glMatrix.mat4.create(), modelViewMatrixInverse);

    normalMats.set(normalMatrix, i * 16);

    let center = glMatrix.vec4.transformMat4(glMatrix.vec3.create(), teapotCenter, modelViewMatrix);
    this.instanceCenters.push(glMatrix.vec3.fromValues(center[0], center[1], center[2]));

    console.log('center ', center)
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=219:242#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:220-243 Create Transformation Matrices for All Teapot Instances</a></div></div><p>For each teapot, we first apply a rotation and then move it to a position such that all instances form a ring. The <code>modelViewMatrix</code> is stored in an array, and similarly, the normal matrices are kept in another array. These arrays are passed into the shader program as:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=69>@group(0) @binding(3)
var&lt;uniform&gt; teapotTransformationMat : array&lt;mat4x4&lt;f32&gt;, 16&gt;;
@group(0) @binding(4)
var&lt;uniform&gt; teapotNormalMat : array&lt;mat4x4&lt;f32&gt;, 16&gt;;
</pre></code><div class="code-fragments-separator">• • •</div><pre><code class="language-javascript code-block" startNumber=107>@vertex
fn vs_main(
    @builtin(instance_index) instanceIdx : u32,
    @location(0) inPos: vec3&lt;f32&gt;,
    @location(1) inNormal: vec3&lt;f32&gt;
    //,@location(2) transformation: mat4x4&lt;f32&gt;
) -&gt; VertexOutput {
    var out: VertexOutput;
    out.viewDir = normalize((normalMatrix * vec4&lt;f32&gt;(-viewDirection, 0.0)).xyz);
    out.lightDir = normalize((normalMatrix * vec4&lt;f32&gt;(-lightDirection, 0.0)).xyz);
    out.normal = normalize(normalMatrix * teapotNormalMat[instanceIdx] * vec4&lt;f32&gt;(inNormal, 0.0)).xyz;  
    
    out.clip_position = projection * modelView * teapotTransformationMat[instanceIdx] * vec4&lt;f32&gt;(inPos, 1.0);

    if (selected == instanceIdx) {
        out.normal = vec3&lt;f32&gt;(0.0, 0.0, 0.0);
    }
    return out;
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=68:71,106:124#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:69-125 In the Vertex Shader, We Apply Different Transformation for Each Teapot Based on Instance Id</a></div></div><p>The vertex shader’s main function includes an input <code>@builtin(instance_index) instanceIdx : u32</code>. Similar to the <code>vertex_index</code> we have seen before, this builtin provides the instance ID. We use this index to retrieve the corresponding transformation and normal matrices for each instance.</p><p>Notice that we also save the transformed teapot centers into an array; they are important for the ray-sphere intersection test.</p><p>Now let’s examine the picking functionality implemented in the mouse event handling functions. Since this demo also supports navigation via arcball, much of the implementation, such as the <code>onmousedown</code> function, is similar to what we covered in the previous chapter. Here, I’ll focus on the differences, particularly the picking logic in the <code>mousemove</code> event handler:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=787>//selection mode
const currX = (x - originX) * 2.0 / width;
const currY = (originY - y) * 2.0 / height;
//https://gamedev.stackexchange.com/questions/17987/what-does-the-graphics-card-do-with-the-fourth-element-of-a-vector-as-the-final
//https://antongerdelan.net/opengl/raycasting.html
//https://gamedev.stackexchange.com/questions/153078/what-can-i-do-with-the-4th-component-of-gl-position
let projectionMatrixInverse = glMatrix.mat4.invert(glMatrix.mat4.create(), projectionMatrix);

let clipSpacePosition = glMatrix.vec4.fromValues(currX, currY, 0.0, 1.0);

let camSpacePosition = glMatrix.vec4.transformMat4(glMatrix.vec4.create(), clipSpacePosition, projectionMatrixInverse);

//clipSpacePosition[2] = -1;
camSpacePosition[3] = 0;

let dir = glMatrix.vec4.transformMat4(glMatrix.vec4.create(), camSpacePosition, modelViewMatrixInverse);

dir = glMatrix.vec3.normalize(glMatrix.vec3.create(), dir);
let found = false;
console.log("select", currX, currY, teapot.instanceCount);
for (let i = 0; i &lt; teapot.instanceCount; ++i) {
    let center = teapot.instanceCenters[i];
    center = glMatrix.vec3.fromValues(center[0] - arcball.forwardVector[0],
        center[1] - arcball.forwardVector[1],
        center[2] - arcball.forwardVector[2]);

    const dot = glMatrix.vec3.dot(center, dir);
    const dis = glMatrix.vec3.length(glMatrix.vec3.subtract(glMatrix.vec3.create(), glMatrix.vec3.scale(glMatrix.vec3.create(), dir, dot), center));
    console.log("dis ", dis);
    if (dis &lt; teapot.teapotRadius) {
        console.log('found teapot ', i, dis, teapot.teapotRadius);
        const selectionUniformBufferUpdate = createGPUBuffer(device, new Uint32Array([i]), GPUBufferUsage.COPY_SRC);
        commandEncoder = device.createCommandEncoder();
        commandEncoder.copyBufferToBuffer(selectionUniformBufferUpdate, 0,
            teapot.selectionUniformBuffer, 0, 4);
        device.queue.submit([commandEncoder.finish()]);
        requestAnimationFrame(render);
        console.log("update selection")
        found = true;
        break;
    }
}
if (!found) {
    const selectionUniformBufferUpdate = createGPUBuffer(device, new Uint32Array([17]), GPUBufferUsage.COPY_SRC);
    commandEncoder = device.createCommandEncoder();
    commandEncoder.copyBufferToBuffer(selectionUniformBufferUpdate, 0,
        teapot.selectionUniformBuffer, 0, 4);
    device.queue.submit([commandEncoder.finish()]);
    requestAnimationFrame(render);
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=786:835#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:787-836 Mousemove Handling for Picking</a></div></div><p>This function includes a condition to check if the mouse is being dragged. If it is, we treat the input as an arcball navigation gesture and update the arcball accordingly. If the mouse is moving without any buttons pressed, we consider it a picking scenario.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=788>const currX = (x - originX) * 2.0 / width;
const currY = (originY - y) * 2.0 / height;
//https://gamedev.stackexchange.com/questions/17987/what-does-the-graphics-card-do-with-the-fourth-element-of-a-vector-as-the-final
//https://antongerdelan.net/opengl/raycasting.html
//https://gamedev.stackexchange.com/questions/153078/what-can-i-do-with-the-4th-component-of-gl-position
let projectionMatrixInverse = glMatrix.mat4.invert(glMatrix.mat4.create(), projectionMatrix);

let clipSpacePosition = glMatrix.vec4.fromValues(currX, currY, 0.0, 1.0);

let camSpacePosition = glMatrix.vec4.transformMat4(glMatrix.vec4.create(), clipSpacePosition, projectionMatrixInverse);

//clipSpacePosition[2] = -1;
camSpacePosition[3] = 0;

let dir = glMatrix.vec4.transformMat4(glMatrix.vec4.create(), camSpacePosition, modelViewMatrixInverse);

dir = glMatrix.vec3.normalize(glMatrix.vec3.create(), dir);
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=787:803#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:788-804 Convert Canvas Location to Ray</a></div></div><p>The purpose of the above code is to convert the current mouse position on the canvas into a ray direction in world space. To understand this, it's important to be familiar with the coordinate transformations in the graphics pipeline. After applying the projection matrix, a 3D point is transformed from camera coordinates into clip space. The clip space position ranges from -1.0 to 1.0 for x, y, and z coordinates. Therefore, the calculations ensure that x and y are within this normalized range.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=788>const currX = (x - originX) * 2.0 / width;
const currY = (originY - y) * 2.0 / height;
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=787:788#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:788-789 Mouse Position to Clip Coordinates</a></div></div><p>For the z-axis, since the screen position is 2D, we need to assign a z value to <code>clipSpacePosition</code>. Here, we use zero. For the w component, recall that in homogeneous coordinates, if the last component is 1.0, it represents a position; otherwise, it represents a direction. For now, let's treat it as a position. We then apply the inverse projection matrix to transform the clip space point into the camera coordinate system. In camera coordinates, the origin is at the camera. Therefore, the ray we cast from the camera through the mouse position into the scene is represented by the point's position minus the origin. We set the camera coordinates' w component to zero because it represents a direction rather than a position. Finally, we apply the inverse model-view matrix to this direction to get the direction in world space and normalize it.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=807>for (let i = 0; i &lt; teapot.instanceCount; ++i) {
    let center = teapot.instanceCenters[i];
    center = glMatrix.vec3.fromValues(center[0] - arcball.forwardVector[0],
        center[1] - arcball.forwardVector[1],
        center[2] - arcball.forwardVector[2]);

    const dot = glMatrix.vec3.dot(center, dir);
    const dis = glMatrix.vec3.length(glMatrix.vec3.subtract(glMatrix.vec3.create(), glMatrix.vec3.scale(glMatrix.vec3.create(), dir, dot), center));
    console.log("dis ", dis);
    if (dis &lt; teapot.teapotRadius) {
        console.log('found teapot ', i, dis, teapot.teapotRadius);
        const selectionUniformBufferUpdate = createGPUBuffer(device, new Uint32Array([i]), GPUBufferUsage.COPY_SRC);
        commandEncoder = device.createCommandEncoder();
        commandEncoder.copyBufferToBuffer(selectionUniformBufferUpdate, 0,
            teapot.selectionUniformBuffer, 0, 4);
        device.queue.submit([commandEncoder.finish()]);
        requestAnimationFrame(render);
        console.log("update selection")
        found = true;
        break;
    }
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=806:827#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:807-828 Detect Intersection Against All Proxy Spheres</a></div></div><p>Next, we loop through all teapots. For each teapot, we calculate the direction from its center to the camera position. We project this vector onto the ray vector and then scale the ray vector by the projected length. Finally, we subtract the teapot’s center vector from the scaled ray vector. The resulting vector, which is perpendicular to the ray vector, represents the shortest distance from the teapot’s center to the ray. If this distance is smaller than the radius of the teapot’s proxy sphere, we consider that the ray intersects the teapot.</p><p>In this case, we update the current selected teapot index in the uniform buffer. In the shader code, if an instance ID matches the current selection, the teapot is rendered in a different color.</p><p>If no selection is detected, we reset the previous selection by setting the current selection ID to 17. Since we only have 16 teapots, no ID will match 17 in the shader, causing all teapots to be rendered normally.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=829>if (!found) {
    const selectionUniformBufferUpdate = createGPUBuffer(device, new Uint32Array([17]), GPUBufferUsage.COPY_SRC);
    commandEncoder = device.createCommandEncoder();
    commandEncoder.copyBufferToBuffer(selectionUniformBufferUpdate, 0,
        teapot.selectionUniformBuffer, 0, 4);
    device.queue.submit([commandEncoder.finish()]);
    requestAnimationFrame(render);
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=828:835#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:829-836 Mark the Selected Teapot in a Uniform Buffer</a></div></div><p>Lastly, let's look at how to encode a draw command for instanced rendering. The advantage of instanced rendering is that it allows us to efficiently duplicate the same geometry, which is ideal for rendering foliage in games or particles. In this example, rendering instanced objects is straightforward. We simply need to specify the total number of instances to render when encoding the draw command. As previously discussed, each instance has its own transformation matrices, which are retrieved from a uniform buffer based on the <code>instanceIdx</code>.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=476>encode(encoder) {
    encoder.setPipeline(this.pipeline);
    encoder.setBindGroup(0, this.uniformBindGroup);
    encoder.setVertexBuffer(0, this.positionBuffer);
    encoder.setVertexBuffer(1, this.normalBuffer);
    encoder.setIndexBuffer(this.indexBuffer, 'uint16');
    encoder.drawIndexed(this.indexSize, this.instanceCount);
    encoder.setPipeline(this.ringPipeline);
    encoder.setBindGroup(0, this.ringUniformBindGroup);
    encoder.setVertexBuffer(0, this.ringPositionBuffer);
    encoder.draw(16, this.instanceCount);
    encoder.setVertexBuffer(0, this.ringPositionBuffer2);
    encoder.draw(16, this.instanceCount);
    encoder.setVertexBuffer(0, this.ringPositionBuffer3);
    encoder.draw(16, this.instanceCount);
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=475:490#3_02_1_picking_ray_casting">3_02_1_picking_ray_casting/index.html:476-491 Instanced Rendering</a></div></div><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_picking_ray.png" original_src="picking_ray.png" alt="Raycasting Object Picking. Picked Object Is in Black." sources='[]' /><div class="img-title">Raycasting Object Picking. Picked Object Is in Black.</div></div></p><h3 >Color coding</h3><a href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html#3_02_2_picking_color_coding" target="_blank" class="comment"><svg style="margin-right:10px;vertical-align: middle;" xmlns="http://www.w3.org/2000/svg" height="32"
                    width="32" fill="#dadadb" viewBox="0 -960 960 960"><path d="M189-160q-60 0-102.5-43T42-307q0-9 1-18t3-18l84-336q14-54 57-87.5t98-33.5h390q55 0 98 33.5t57 87.5l84 336q2 9 3.5 18.5T919-306q0 61-43.5 103.5T771-160q-42 0-78-22t-54-60l-28-58q-5-10-15-15t-21-5H385q-11 0-21 5t-15 15l-28 58q-18 38-54 60t-78 22Zm3-80q19 0 34.5-10t23.5-27l28-57q15-31 44-48.5t63-17.5h190q34 0 63 18t45 48l28 57q8 17 23.5 27t34.5 10q28 0 48-18.5t21-46.5q0 1-2-19l-84-335q-7-27-28-44t-49-17H285q-28 0-49.5 17T208-659l-84 335q-2 6-2 18 0 28 20.5 47t49.5 19Zm348-280q17 0 28.5-11.5T580-560q0-17-11.5-28.5T540-600q-17 0-28.5 11.5T500-560q0 17 11.5 28.5T540-520Zm80-80q17 0 28.5-11.5T660-640q0-17-11.5-28.5T620-680q-17 0-28.5 11.5T580-640q0 17 11.5 28.5T620-600Zm0 160q17 0 28.5-11.5T660-480q0-17-11.5-28.5T620-520q-17 0-28.5 11.5T580-480q0 17 11.5 28.5T620-440Zm80-80q17 0 28.5-11.5T740-560q0-17-11.5-28.5T700-600q-17 0-28.5 11.5T660-560q0 17 11.5 28.5T700-520Zm-360 60q13 0 21.5-8.5T370-490v-40h40q13 0 21.5-8.5T440-560q0-13-8.5-21.5T410-590h-40v-40q0-13-8.5-21.5T340-660q-13 0-21.5 8.5T310-630v40h-40q-13 0-21.5 8.5T240-560q0 13 8.5 21.5T270-530h40v40q0 13 8.5 21.5T340-460Zm140-20Z"/></svg>Launch Playground - 3_02_2_picking_color_coding</a><p>Ray casting is relatively simple to implement but has limitations in some scenarios. For example, proxy geometries often lack the detail of the actual objects, which can affect precision in picking. Additionally, the ray casting method we implemented does not account for occlusion; a distant and occluded object might still be picked if it is encountered first during intersection detection. Furthermore, in cases where objects have a single side, such as a plane with only a front face, the object should not be visible when facing away from the viewer if we cull its back face. However, ray picking would still select it. Lastly, with many objects, ray casting can become slow, especially when many objects are obscured or outside the view. This issue can be mitigated by using more efficient scene data structures like a kd-tree, which limits ray intersection tests to objects that are likely to intersect with the ray.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_colorpicking.png" original_src="colorpicking.png" alt="An Illustration of a Color Coded 3D Scene" sources='[]' /><div class="img-title">An Illustration of a Color Coded 3D Scene</div></div></p><p>In this section, we will explore an alternative picking method called color coding, which addresses some of these issues. The principle of color coding is straightforward: we encode each object's ID as a unique color. With RGB colors, we can represent up to 2^24 objects, which is sufficient for most use cases. We render the scene using these unique colors and then read back the rendered image. During this step, it is important to avoid processes that could alter color values, such as blending or anti-aliasing. After rendering, we can retrieve object IDs from the colors by checking the color under the mouse cursor. Instead of reading the entire image, it is sufficient to sample a small area around the cursor. Additionally, rendering at a reduced resolution can enhance performance, as picking does not typically require pixel-level accuracy.</p><p>The benefits of color coding are clear: by rendering the scene with unique colors, only the frontmost and visible object is considered for selection. This method also avoids the need for proxy geometries, allowing for precise picking with the actual geometry. However, unlike ray casting, color coding requires coordination between shader code and JavaScript code.</p><p>Now, let’s look at the code:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=42>@vertex
fn vs_main(
    @builtin(instance_index) instanceIdx : u32,
    @location(0) inPos: vec3&lt;f32&gt;,
    @location(1) color: vec4&lt;u32&gt;
) -&gt; VertexOutput {
    var out: VertexOutput;
    out.clip_position = projection * modelView * teapotTransformationMat[instanceIdx] * vec4&lt;f32&gt;(inPos, 1.0);
    out.color = color.xyz;
    return out;
}

// Fragment shader

@fragment
fn fs_main(in: VertexOutput) -&gt; @location(0) vec4&lt;u32&gt; {
    return vec4&lt;u32&gt;( in.color.xyz ,255);
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=41:58#3_02_2_picking_color_coding">3_02_2_picking_color_coding/index.html:42-59 Shader to Render Color Coded Objects</a></div></div><p>There are two shaders involved in this process. The first shader is the normal rendering shader, which we will skip. The second shader is used for color-coded rendering, which is actually simpler. Color codes are passed in via vertex attributes and then to the fragment shader, which renders these colors. The transparency channel is set to fully opaque, and the output format is u32 to avoid scaling color values to floating-point numbers, which could alter the color codes.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=666>bufferWidth = (Math.floor(2 * 4 / 256.0) + 1) * 256;
copiedBuffer = createGPUBuffer(device, new Uint8Array(bufferWidth * 2), GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);
</pre></code><div class="code-fragments-separator">• • •</div><pre><code class="language-javascript code-block" startNumber=669>async function pick(x, y) {
    if (inRendering) {
        return 17;
    }
    inRendering = true;
</pre></code><div class="code-fragments-separator">• • •</div><pre><code class="language-javascript code-block" startNumber=701>passEncoder = commandEncoder.beginRenderPass(renderPassDescColorCode);

passEncoder.setViewport(0, 0, canvas.width, canvas.height, 0, 1);
teapot.encodeForColorCoding(passEncoder);

passEncoder.end();
commandEncoder.copyTextureToBuffer({ texture: colorCodeTexture, origin: { x, y } }, { buffer: copiedBuffer, bytesPerRow: bufferWidth }, { width: 2, height: 2 });
device.queue.submit([commandEncoder.finish()]);

await device.queue.onSubmittedWorkDone();
</pre></code><div class="code-fragments-separator">• • •</div><pre><code class="language-javascript code-block" startNumber=719>        await copiedBuffer.mapAsync(GPUMapMode.READ, 0, bufferWidth * 2);
        //const imageData = new ImageData(new Uint8ClampedArray(copiedBuffer.getMappedRange()), bufferWidth / 4, 2);

        const d = new Uint8ClampedArray(copiedBuffer.getMappedRange());
        const picked = d[0];
        console.log('pick ', picked);

        copiedBuffer.unmap();
        inRendering = false;

        return picked;
    }

    return 17;
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=665:666,668:672,700:709,718:732#3_02_2_picking_color_coding">3_02_2_picking_color_coding/index.html:666-733 The Picking Routine</a></div></div><p>Firstly, to prevent the pick function from being called while a previous call is still processing, we use a flag <code>inRendering</code>. This ensures that temporary buffers are not written to while being mapped, avoiding potential issues.</p><p>After rendering, we copy the framebuffer to a temporary <code>copiedBuffer</code>. This buffer is smaller than the framebuffer, and we only copy a 2x2 window around the current mouse cursor. Note that the <code>bytesPerRow</code> parameter must be a multiple of 256, according to the specification, so we allocate more space than necessary to comply with this requirement.</p><p>Once the command queue is completed, we map the copied buffer for read access. While a more sophisticated implementation might analyze the most dominant color to determine the most likely object, this example simply checks the red channel of the first pixel. Given that there are only 16 objects in the demo, the red channel alone suffices to identify the object index, so this approach is used for simplicity.</p><p>Let's now examine the pipeline setup code, specifically how we encode object indices into colors when setting up teapot instances. We encode the object index into RGB values using little-endian format.</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=188>for (let i = 0; i &lt; this.instanceCount; ++i) {
</pre></code><div class="code-fragments-separator">• • •</div><pre><code class="language-javascript code-block" startNumber=209>    colorCodes.set([i &amp; 0b11111111,
    (i &gt;&gt; 8) &amp; 0b11111111, (i &gt;&gt; 16) &amp; 0b11111111, (i &gt;&gt; 24) &amp; 0b11111111], i * 4 + 0);
}
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=187:187,208:210#3_02_2_picking_color_coding">3_02_2_picking_color_coding/index.html:188-211 Setting Color Codes</a></div></div><p>The final step is creating the target texture for rendering the color-coded scene:</p><div class="code-fragments"><pre><code class="language-javascript code-block" startNumber=649>const colorCodeTextureDesc = {
    size: [canvas.width, canvas.height, 1],
    dimension: '2d',
    format: 'rgba8uint',
    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_SRC
};

colorCodeTexture = device.createTexture(colorCodeTextureDesc);

let colorCodeTextureView = colorCodeTexture.createView();

colorCodeAttachment = {
    view: colorCodeTextureView,
    clearValue: { r: 1, g: 0, b: 0, a: 1 },
    loadOp: 'clear',
    storeOp: 'store'
};
</pre></code><div class="code-fragments-caption"><a target="_blank" href="https://shi-yan.github.io/WebGPUUnleashed/code/code.html?highlight=648:664#3_02_2_picking_color_coding">3_02_2_picking_color_coding/index.html:649-665 Configuring the Temporary Render Target</a></div></div><p>We use the <code>rgba8unorm</code> format for the texture to match the shader's output format. For the read-back buffer, note how we determine bufferWidth. Although a single row of a 2x2 window requires only 4 * 2 bytes, it must be rounded up to the nearest multiple of 256. This is a requirement for <code>GPUImageCopyBuffer</code>.</p><p>This concludes the picking setup. The normal rendering part, which we have chosen to omit, complements this process.</p><p><div class="img-container"><img class="img" onclick="openImage(this)" src="thumb_picking_color_coding.png" original_src="picking_color_coding.png" alt="Object Picking Based on Color Coding Doesn't Need Proxy Geometries" sources='[]' /><div class="img-title">Object Picking Based on Color Coding Doesn't Need Proxy Geometries</div></div></p>
        </article>

        <div class="older_newer_link_section">
            <div class="older_newer_link_left">
                <p>
                    <svg xmlns="http://www.w3.org/2000/svg" height="12" width="11" fill="#dadadb"
                        viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
                        <path
                            d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" />
                    </svg>
                    PREV POST
                </p>
                <p>
                    <a class="older_newer_link" href="/WebGPUUnleashed/Control/arcball_camera_control.html">Arcball Camera Control</a>
                </p>
            </div>

            <div class="older_newer_link_right">
                <p>
                    NEXT POST
                    <svg xmlns="http://www.w3.org/2000/svg" height="12" width="11" fill="#dadadb"
                        viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
                        <path
                            d="M438.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-160-160c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L338.8 224 32 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l306.7 0L233.4 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l160-160z" />
                    </svg>
                </p>
                <p>
                    <a class="older_newer_link" href="/WebGPUUnleashed/Control/saving_images_and_videos.html">Saving Images and Videos</a>
                </p>
            </div>
        </div>

        <a href="https://github.com/shi-yan/WebGPUUnleashed/discussions" target="_blank" class="comment"><svg
            style="margin-right:10px;vertical-align: middle;" xmlns="http://www.w3.org/2000/svg" height="32"
            width="32" fill="#dadadb"
            viewBox="0 0 480 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.-->
            <path
                d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z" />
        </svg> Leave a Comment on Github</a>
    </div>
    <!-- The Modal -->
    <div id="img-modal" class="modal">
        <!-- The Close Button -->
        <span class="close" id="img-close">&times;</span>
        <!-- Modal Content (The Image) -->
        <img class="modal-content" id="img01">

        <!-- Modal Caption (Image Text) -->
        <div id="caption"></div>
    </div>
    <script>
        function fold(e) {
            const sub = e.currentTarget.parentElement.getElementsByTagName("ul")[0];
            console.log("sub", e.currentTarget, sub);
            if (sub.style.display === "block") {
                sub.style.display = "none";
            } else {
                sub.style.display = "block";
            }
        }
    
        window.addEventListener('click', (e) => {
           // const sub = e.currentTarget.parentElement.getElementsByTagName("ul")[0];
            document.getElementById("menuButton").checked = false;
        });
    
        document.getElementById("menu-container").addEventListener('click',(event) => {
            event.stopPropagation();
        });

        document.getElementById("menuButton").addEventListener('click', (event) => {
            event.stopPropagation();
        });
       
        function openImage(img) {
            let modal = document.getElementById("img-modal");
            let modalImg = document.getElementById("img01");
            modal.style.display = "block";
            if (img.getAttribute("original_src")) {
                modalImg.src = img.getAttribute("original_src");
            } else {
                modalImg.src = img.src;
            }
            let captionText = document.getElementById("caption");

            captionText.innerText = img.alt;

            let sources = JSON.parse(img.getAttribute("sources"));

            for (let i = 0; i < sources.length; ++i) {
                if (sources.length == 1) {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE</a>";
                } else {
                    captionText.innerHTML += "<a href='" + sources[i] + "' target='_blank' class='img-source'>SOURCE " + (i + 1) + "</a>";
                }
            }
        }
        // Get the <span> element that closes the modal
        var closeButton = document.getElementById("img-close");

        // When the user clicks on <span> (x), close the modal
        closeButton.onclick = function () {
            var modal = document.getElementById("img-modal");
            modal.style.display = "none";
        }
    </script>

    <script type="module">
        const macros = {};
        const mathElementsBlock = document.getElementsByClassName("math-block");
        for (let element of mathElementsBlock) {
            katex.render(element.textContent, element, {
                throwOnError: false,
                displayMode: true,
                macros
            });
        }

        const mathElementsInline = document.getElementsByClassName("math-inline");
        for (let element of mathElementsInline) {
            katex.render(element.textContent, element, {
                throwOnError: false,
                macros
            });
        }

        hljs.highlightAll();
        // hljs.initLineNumbersOnLoad();
        const codeBlocks = document.getElementsByClassName("code-block");
        for (let i = 0; i < codeBlocks.length; ++i) {
            if (codeBlocks[i].hasAttribute("startnumber")) {
                const startFrom = codeBlocks[i].getAttribute("startnumber");
                hljs.lineNumbersBlock(codeBlocks[i], { startFrom: parseInt(startFrom, 10) });
            } else {
                hljs.lineNumbersBlock(codeBlocks[i]);
            }
        }

    </script>
</body>

</html>